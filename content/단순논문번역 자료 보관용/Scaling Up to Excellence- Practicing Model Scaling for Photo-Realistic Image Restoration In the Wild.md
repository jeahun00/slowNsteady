# Abstract
SUPIR(Scaling-UP Image Restoration)를 소개합니다. 이는 generative prior와 모델의 확장력을 활용한 획기적인 이미지 복원 방법입니다. 멀티 모달 기법과 고급 generative prior를 활용하여, SUPIR는 지능적이고 현실적인 이미지 복원에서 중요한 진전을 이룹니다. SUPIR의 핵심 촉매제로서 모델 확장은 그 능력을 극적으로 향상시키며 이미지 복원의 새로운 잠재력을 보여줍니다. 우리는 모델 학습을 위해 2천만 개의 고해상도, 고품질 이미지로 구성된 데이터셋을 수집하였으며, 각각의 이미지에는 설명 텍스트 주석이 추가되어 있습니다. SUPIR는 텍스트 프롬프트에 따라 이미지를 복원하는 기능을 제공하여 응용 범위와 잠재력을 넓힙니다. 더불어, 지각 품질을 더욱 향상시키기 위해 부정적인 품질 프롬프트도 도입하였습니다. 우리는 생성 기반 복원에서 발생하는 충실도 문제를 억제하기 위해 복원 유도 샘플링 방법도 개발하였습니다. 실험 결과, SUPIR의 뛰어난 복원 효과와 텍스트 프롬프트를 통한 복원 조작의 새로운 능력을 입증합니다.

## 1. Introduction

이미지 복원(IR)의 발전은 IR 결과의 지각적 효과와 지능에 대한 기대를 크게 높였습니다. Generative priors [42, 49, 67, 82]를 기반으로 한 IR 방법은 강력한 사전 학습된 생성 모델을 활용하여 IR에 고품질 생성 및 사전 지식을 도입함으로써 이 분야에서 큰 진전을 이루고 있습니다. Generative prior의 능력을 지속적으로 향상시키는 것은 더 나은 IR 결과를 달성하기 위한 핵심이며, 모델 확장이 중요한 효과적인 접근법입니다. SAM [44]과 대형 언어 모델(LLMs) [7, 73, 74]과 같은 많은 태스크가 확장을 통해 놀라운 개선을 이루었습니다. 이는 초고품질 이미지를 생성할 수 있는 대규모 지능형 IR 모델을 구축하려는 우리의 추구를 더욱 가속화합니다. 그러나 컴퓨팅 자원, 모델 구조, 학습 데이터 및 generative 모델과 IR의 협력과 같은 엔지니어링 제약으로 인해 IR 모델을 확장하는 것은 도전적입니다.

본 연구에서는 이미지 복원 시각 효과와 지능에서 더 큰 잠재력을 탐구하기 위해 최대 규모의 IR 방법인 SUPIR(Scaling-UP IR)를 소개합니다. 구체적으로, SUPIR는 26억 개의 파라미터를 포함하는 강력한 generative prior인 StableDiffusion-XL (SDXL) [63]을 사용합니다. 이 모델을 IR에 효과적으로 배포하기 위해, 우리는 ZeroSFT 커넥터라는 새로운 구성 요소를 포함하는 대규모 어댑터를 설계하고 훈련시켰습니다. 모델 확장의 이점을 최대한 활용하기 위해, 우리는 각각 상세한 설명 텍스트가 첨부된 2천만 개 이상의 고품질, 고해상도 이미지를 포함하는 데이터셋을 수집하였습니다. 우리는 이미지 콘텐츠 프롬프트를 제공하기 위해 130억 개의 파라미터를 가진 멀티모달 언어 모델을 활용하여 방법의 정확성과 지능을 크게 향상시켰습니다. 제안된 SUPIR 모델은 다양한 IR 태스크에서 뛰어난 성능을 보여주며, 특히 복잡하고 도전적인 실제 시나리오에서 최고의 시각적 품질을 달성합니다. 추가로, 이 모델은 텍스트 프롬프트를 통해 복원 프로세스에 대한 유연한 제어를 제공하여 IR의 가능성을 크게 확장합니다. 그림 1은 우리 모델의 효과를 보여줍니다.

## 1. 서론

이미지 복원(IR)의 발전은 IR 결과의 지각적 효과와 지능에 대한 기대를 크게 높였습니다. Generative priors [42, 49, 67, 82]를 기반으로 한 IR 방법은 강력한 사전 학습된 생성 모델을 활용하여 IR에 고품질 생성 및 사전 지식을 도입함으로써 이 분야에서 큰 진전을 이루고 있습니다. Generative prior의 능력을 지속적으로 향상시키는 것은 더 나은 IR 결과를 달성하기 위한 핵심이며, 모델 확장이 중요한 효과적인 접근법입니다. SAM [44]과 대형 언어 모델(LLMs) [7, 73, 74]과 같은 많은 태스크가 확장을 통해 놀라운 개선을 이루었습니다. 이는 초고품질 이미지를 생성할 수 있는 대규모 지능형 IR 모델을 구축하려는 우리의 추구를 더욱 가속화합니다. 그러나 컴퓨팅 자원, 모델 구조, 학습 데이터 및 generative 모델과 IR의 협력과 같은 엔지니어링 제약으로 인해 IR 모델을 확장하는 것은 도전적입니다.

본 연구에서는 이미지 복원 시각 효과와 지능에서 더 큰 잠재력을 탐구하기 위해 최대 규모의 IR 방법인 SUPIR(Scaling-UP IR)를 소개합니다. 구체적으로, SUPIR는 26억 개의 파라미터를 포함하는 강력한 generative prior인 StableDiffusion-XL (SDXL) [63]을 사용합니다. 이 모델을 IR에 효과적으로 배포하기 위해, 우리는 ZeroSFT 커넥터라는 새로운 구성 요소를 포함하는 대규모 어댑터를 설계하고 훈련시켰습니다. 모델 확장의 이점을 최대한 활용하기 위해, 우리는 각각 상세한 설명 텍스트가 첨부된 2천만 개 이상의 고품질, 고해상도 이미지를 포함하는 데이터셋을 수집하였습니다. 우리는 이미지 콘텐츠 프롬프트를 제공하기 위해 130억 개의 파라미터를 가진 멀티모달 언어 모델을 활용하여 방법의 정확성과 지능을 크게 향상시켰습니다. 제안된 SUPIR 모델은 다양한 IR 태스크에서 뛰어난 성능을 보여주며, 특히 복잡하고 도전적인 실제 시나리오에서 최고의 시각적 품질을 달성합니다. 추가로, 이 모델은 텍스트 프롬프트를 통해 복원 프로세스에 대한 유연한 제어를 제공하여 IR의 가능성을 크게 확장합니다. 그림 1은 우리 모델의 효과를 보여줍니다.

## 2. Related Works

**Image Restoration.** IR의 목표는 열화된 이미지를 고품질의 열화 없는 이미지로 변환하는 것입니다 [22, 26, 89, 91, 98, 99]. 초기 단계에서 연구자들은 독립적으로 초해상도(SR) [13, 19, 20], 노이즈 제거 [11, 90, 92], 디블러링 [14, 60, 72] 등의 다양한 유형의 이미지 열화를 탐구했습니다. 그러나 이러한 방법들은 종종 특정 열화 가정을 기반으로 하기 때문에 [25, 50, 58], 다른 열화에 대한 일반화 능력이 부족합니다 [29, 53, 97? ]. 시간이 지남에 따라 특정 열화 가정을 기반으로 하지 않는 블라인드 IR 방법의 필요성이 커졌습니다 [5, 10, 25, 34, 35, 46–48, 94]. 이러한 추세에서 일부 방법들은 [81, 93] 보다 복잡한 열화 모델을 통해 실제 열화를 합성하여 단일 모델로 여러 열화를 처리하는 것으로 잘 알려져 있습니다. DiffBIR [49]은 다양한 복원 문제를 단일 모델로 통합합니다. 본 논문에서는 DiffBIR과 유사한 설정을 채택하여 단일 모델로 다양한 심각한 열화를 효과적으로 처리합니다.

**Generative Prior.** Generative priors는 이미지의 고유 구조를 캡처하여 자연 이미지 분포를 따르는 이미지를 생성할 수 있습니다. GANs [23, 39, 40, 64]의 등장은 IR에서 generative priors의 중요성을 강조했습니다. 다양한 접근법이 generative priors를 사용하며, 여기에는 GAN inversion [2, 4, 27, 57, 62], GAN 인코더 [9, 103], 또는 IR의 핵심 모듈로 GAN을 사용하는 것 [80, 87]이 포함됩니다. GANs 외에도 다른 generative 모델들도 priors로 사용할 수 있습니다 [10, 36, 55, 75, 100–102]. 우리의 연구는 주로 확산 모델 [31, 61, 65, 67, 70, 71]에서 파생된 generative priors에 초점을 맞추고 있으며, 이는 제어 가능한 생성 [15, 18, 32, 59, 95]과 모델 확장 [63, 66, 68]에서 뛰어납니다. 확산 모델은 또한 IR에서 generative priors로 효과적으로 사용되고 있습니다 [42, 49, 67, 77, 82]. 그러나 이러한 확산 기반 IR 방법의 성능은 사용된 generative 모델의 규모에 의해 제한되어, 그 효과를 더욱 향상시키는 데 어려움을 겪고 있습니다.

**Model Scaling** 은 딥러닝 모델의 능력을 더욱 향상시키기 위한 중요한 수단입니다. 가장 대표적인 예로는 언어 모델 [7, 73, 74], 텍스트-이미지 생성 모델 [12, 37, 63, 67, 68, 85], 그리고 이미지 분할 모델 [44]의 확장을 들 수 있습니다. 이러한 모델들의 규모와 복잡성은 기하급수적으로 증가하여 수십억 개의 파라미터를 포함하게 되었습니다. 파라미터의 증가는 또한 성능의 큰 향상을 가져와 모델 확장의 엄청난 잠재력을 보여주고 있습니다 [38]. 그러나 모델 확장은 모델 설계, 데이터 수집, 컴퓨팅 자원 및 기타 제한 사항을 포함하는 체계적인 문제입니다. 많은 다른 태스크들은 아직 모델 확장이 가져다주는 상당한 성능 향상을 누리지 못하고 있습니다. IR이 그 중 하나입니다.

## 3. Method

제안된 SUPIR 방법의 개요는 그림 2에 나와 있습니다. 우리는 세 가지 측면에서 우리의 방법을 소개합니다: 
섹션 3.1에서는 네트워크 설계와 훈련 방법을 소개합니다; 
섹션 3.2에서는 훈련 데이터의 수집과 텍스트 모달리티의 도입을 소개합니다; 
그리고 섹션 3.3에서는 IR을 위한 확산 샘플링 방법을 소개합니다.

## 3.1. 모델 확장

**Generative Prior.** 대규모 generative 모델을 위해 선택할 수 있는 옵션은 많지 않습니다. 고려할 수 있는 유일한 모델은 Imagen [68], IF [16], 그리고 SDXL [63]입니다. 우리는 다음과 같은 이유로 SDXL을 선택했습니다. Imagen과 IF는 텍스트-이미지 생성을 우선시하며 계층적 접근 방식을 따릅니다. 이들은 먼저 저해상도 이미지를 생성하고 이를 계층적으로 업샘플링합니다. SDXL은 계층적 설계 없이 고해상도 이미지를 직접 생성하여 텍스트 해석에 집중하기보다는 파라미터를 사용하여 이미지 품질을 개선하는 데 중점을 둡니다. 또한, SDXL은 Base-Refine 전략을 사용합니다. Base 모델에서는 다양한 저품질 이미지가 생성됩니다. 그 후, Refine 모델은 품질은 높지만 다양성이 적은 훈련 이미지를 활용하여 이미지를 개선합니다. 우리의 고품질 이미지 대량 데이터셋을 사용한 훈련 접근 방식에서는 SDXL의 이중 단계 설계가 불필요해집니다. 우리는 파라미터 수가 더 많은 Base 모델을 선택하여 이를 이상적인 generative prior로 삼습니다.
### Degradation-Robust Encoder
SDXL에서는 확산 생성 과정이 잠재 공간에서 수행됩니다. 이미지는 사전 학습된 인코더를 통해 먼저 잠재 공간에 매핑됩니다. 사전 학습된 SDXL을 효과적으로 활용하기 위해, 저품질(LQ) 이미지 $x_{LQ}$도 동일한 잠재 공간에 매핑되어야 합니다. 그러나 원래 인코더가 저품질 이미지에 대해 학습되지 않았기 때문에 이를 인코딩에 사용하면 모델이 저품질 이미지 콘텐츠를 잘못 판단하고 아티팩트를 이미지 콘텐츠로 오해할 수 있습니다 [49]. 이를 해결하기 위해, 우리는 인코더를 미세 조정하여 열화에 강하게 만들고자 합니다. 이를 위해, 다음 식을 최소화하여 인코더를 미세 조정합니다:

$$
\mathcal{L}_{E} = \left\| \mathcal{D}(\mathcal{E}_{dr}(x_{LQ})) - \mathcal{D}(\mathcal{E}_{dr}(x_{GT})) \right\|_2^2
$$
여기서, $\mathcal{E}_{dr}$는 미세 조정할 열화-강인 인코더이고, $\mathcal{D}$는 고정된 디코더이며, $x_{GT}$는 그라운드 트루스입니다.

### Large-Scale Adaptor Deisgn.
선택한 사전 학습 모델인 SDXL을 고려할 때, 우리는 제공된 저품질(LQ) 입력에 따라 이미지를 복원할 수 있는 어댑터가 필요합니다. 어댑터는 LQ 이미지의 내용을 식별하고 픽셀 수준에서 생성 제어를 세밀하게 수행해야 합니다. LoRA [32], T2I 어댑터 [59], 그리고 ControlNet [95]는 기존의 확산 모델 적응 방법들이지만, 이들 중 어느 것도 우리의 요구 사항을 충족하지 못합니다. LoRA는 생성에 한계를 가지며 LQ 이미지 제어에 어려움을 겪고, T2I는 LQ 이미지 콘텐츠 식별 능력이 부족하며, ControlNet의 직접 복사는 SDXL 모델 규모에 도전적입니다.

이 문제를 해결하기 위해, 우리는 두 가지 주요 특징을 가진 새로운 어댑터를 설계했습니다. 첫째, 우리는 ControlNet의 고수준 설계를 유지하되, 훈련 가능한 복사본 내의 일부 블록을 직접 트림하여 [33] 엔지니어링이 가능한 구현을 달성했습니다. SDXL의 인코더 모듈 내의 각 블록은 여러 Vision Transformer (ViT) [21] 블록으로 주로 구성되어 있습니다. 우리는 ControlNet의 효과에 기여하는 두 가지 주요 요소를 확인했습니다: 큰 네트워크 용량과 훈련 가능한 복사본의 효율적인 초기화. 특히, 훈련 가능한 복사본의 블록을 부분적으로 트림하더라도 어댑터의 이러한 중요한 특성을 유지합니다. 따라서 우리는 각 인코더 블록에서 ViT 블록의 절반을 단순히 트림합니다.

둘째, 우리는 어댑터를 SDXL에 연결하는 커넥터를 재설계했습니다. SDXL의 생성 능력은 뛰어난 시각적 효과를 제공하지만 픽셀 수준의 제어를 어렵게 만듭니다. ControlNet은 생성 지침을 위해 제로 컨볼루션을 사용하지만, IR에 필요한 제어에는 불충분합니다. LQ 지침의 영향을 증폭하기 위해, 우리는 ZeroSFT 모듈을 도입했습니다. Zero 컨볼루션을 기반으로 구축된 ZeroSFT는 추가적인 공간 특성 전송(SFT) [79] 작업과 그룹 정규화 [84]를 포함합니다.

## 3.2. 훈련 데이터 확장

**Image Collection.** 모델의 확장은 훈련 데이터의 확장을 필요로 합니다 [38]. 그러나 현재 IR을 위해 사용 가능한 대규모 고품질 이미지 데이터셋은 없습니다. DIV2K [3]와 LSDIR [1]은 높은 이미지 품질을 제공하지만, 수량이 제한적입니다. ImageNet (IN) [17], LAION-5B [69], SA-1B [44]와 같은 더 큰 데이터셋은 더 많은 이미지를 포함하고 있지만, 그 이미지 품질은 우리의 높은 기준을 충족하지 못합니다. 이를 위해, 우리는 2천만 개의 고해상도 이미지를 포함하는 대규모 데이터셋을 수집했으며, 이들은 각각 1024×1024 고품질의 텍스처가 풍부한 이미지입니다. 수집된 데이터셋과 기존 데이터셋의 규모 비교는 그림 3에 나와 있습니다. 우리는 또한 모델의 얼굴 복원 성능을 향상시키기 위해 FFHQ-raw 데이터셋 [40]에서 정렬되지 않은 추가적인 7만 개의 고해상도 얼굴 이미지를 포함시켰습니다. 그림 5(a)에서는 우리의 데이터가 다른 잘 알려진 데이터셋에 비해 상대적인 규모를 보여줍니다.

### Multi-Modality Language Guidance
Diffusion 모델은 텍스트 프롬프트를 기반으로 이미지를 생성하는 능력으로 잘 알려져 있습니다. 우리는 텍스트 프롬프트가 IR에도 도움이 될 수 있다고 믿습니다: (1) 이미지 콘텐츠를 이해하는 것은 IR에 매우 중요합니다. 기존 프레임워크는 종종 이러한 이해를 간과하거나 암묵적으로 처리합니다 [24, 29]. 텍스트 프롬프트를 통합함으로써, 우리는 LQ 이미지에 대한 이해를 IR 모델에 명시적으로 전달하여 누락된 정보의 목표 복원을 용이하게 합니다. (2) 심각한 열화의 경우, 최고의 IR 모델조차도 완전히 손실된 정보를 복구하는 데 어려움을 겪습니다. 이러한 경우 텍스트 프롬프트는 제어 메커니즘으로 작용하여 사용자 선호에 기반한 누락된 정보의 목표 복원을 가능하게 합니다. (3) 텍스트를 통해 원하는 이미지 품질을 설명할 수 있어 출력의 지각 품질을 더욱 향상시킬 수 있습니다. 예시를 그림 1(b)에서 볼 수 있습니다.

이를 위해 두 가지 주요 수정 사항을 도입했습니다. 첫째, 우리는 전체 프레임워크를 수정하여 LLaVA 멀티모달 LLM [52]을 파이프라인에 통합했습니다(그림 2 참조). LLaVA는 열화-강인 LQ 이미지 $x_{LQ} = \mathcal{D}(\mathcal{E}_{dr}(x_{LQ}))$를 입력으로 받아 이미지 내 콘텐츠를 명확히 이해하고 이를 텍스트 설명의 형태로 출력합니다. 이러한 설명은 복원을 안내하는 프롬프트로 사용됩니다. 이 과정은 테스트 시 자동화되어 수동 개입의 필요성을 없앱니다. 둘째, PixART [12]의 접근 방식을 따라, 모든 훈련 이미지에 대한 텍스트 주석을 수집하여 모델 훈련 시 텍스트 제어의 역할을 강화했습니다. 이 두 가지 변경 사항은 SUPIR가 이미지 콘텐츠를 이해하고 텍스트 프롬프트를 기반으로 이미지를 복원할 수 있는 능력을 부여합니다.

### Negative-Quality Samples Prompt.
Classifier-free guidance (CFG) [30]는 모델에 원하지 않는 콘텐츠를 지정하는 부정적 프롬프트를 사용하여 제어하는 또 다른 방법을 제공합니다. 우리는 이 기능을 사용하여 모델이 저품질 이미지를 생성하지 않도록 지정할 수 있습니다. 구체적으로, 확산의 각 단계에서 긍정적 프롬프트(pos)와 부정적 프롬프트(neg)를 사용하여 두 가지 예측을 수행하고, 이 두 결과를 융합하여 최종 출력을 $z_{t-1}$로 만듭니다:


$$z_{t-1}^{\text{pos}} = \mathcal{H}(z_t, z_{LQ}, \sigma_t, \text{pos}), \quad z_{t-1}^{\text{neg}} = \mathcal{H}(z_t, z_{LQ}, \sigma_t, \text{neg}),$$
$$z_{t-1} = z_{t-1}^{\text{pos}} + \lambda_{\text{cfg}} \times (z_{t-1}^{\text{pos}} - z_{t-1}^{\text{neg}}),$$

여기서 $\mathcal{H}(\cdot)$는 어댑터가 있는 우리의 확산 모델이며, $\sigma_t$는 시간 단계 $t$에서의 노이즈 분산, $\lambda_{\text{cfg}}$는 하이퍼파라미터입니다. 우리의 프레임워크에서 pos는 긍정적인 품질의 단어로 된 이미지 설명이고, neg는 부정적인 품질의 단어입니다. 예를 들어, "유화, 만화, 흐림, 더러움, 어수선함, 저품질, 변형, 저해상도, 과도한 부드러움"과 같은 단어들입니다.

긍정적 및 부정적 방향을 예측하는 정확성은 CFG 기술에 매우 중요합니다. 그러나 훈련 데이터에 부정적 품질 샘플과 프롬프트가 없으면, 미세 조정된 SUPIR이 부정적 프롬프트를 이해하지 못하게 되어 실패할 수 있습니다. 따라서 샘플링 중에 부정적 품질 프롬프트를 사용하는 것은 아티팩트를 도입할 수 있습니다(예시는 그림 4 참조). 이 문제를 해결하기 위해, 우리는 SDXL을 사용하여 부정적 품질 프롬프트에 해당하는 10만 개의 이미지를 생성했습니다. 우리는 직관적으로 이러한 저품질 이미지를 훈련 데이터에 추가하여 부정적 품질 개념이 제안된 SUPIR 모델에 의해 학습되도록 보장합니다.

### 3.3. Restoration-Guided Sampling
강력한 generative prior는 양날의 검으로, 과도한 생성 능력은 복원된 이미지의 충실도에 영향을 미칠 수 있습니다. 이는 IR 태스크와 생성 태스크 사이의 근본적인 차이를 강조합니다. 우리는 이미지 복원이 LQ 이미지에 충실하도록 생성 범위를 제한할 수단이 필요합니다. 우리는 EDM 샘플링 방법 [41]을 수정하고 이 문제를 해결하기 위해 복원 유도 샘플링 방법을 제안했습니다. 우리는 확산의 각 단계에서 예측 결과 $z_{t-1}$가 LQ 이미지 $z_{LQ}$에 가깝도록 선택적으로 유도하고자 합니다.

구체적인 알고리즘은 알고리즘 1에 나와 있으며, 여기서 $T$는 총 단계 수이고, $\{ \sigma_t \}_{t=1}^T$는 $T$ 단계에 대한 노이즈 분산입니다. $c$는 추가 텍스트 프롬프트 조건입니다. $\tau_r$, $S_{\text{churn}}$, $S_{\text{noise}}$, $S_{\text{min}}$, $S_{\text{max}}$는 다섯 개의 하이퍼파라미터이며, $\tau_r$만이 복원 유도와 관련이 있고, 나머지는 원래 EDM 방법 [41]과 동일하게 유지됩니다.

이해를 돕기 위해 간단한 다이어그램은 그림 5(b)에 나와 있습니다. 우리는 예측 출력 $\hat{z}_{t-1}$과 LQ 잠재 $z_{LQ}$ 사이의 가중치 보간을 복원 유도 출력 $z_{t-1}$로 수행합니다. 이미지의 저주파 정보는 주로 확산 예측의 초기 단계에서 생성되므로 [67], $t$와 $\sigma_t$가 비교적 크고, 가중치 $k = (\sigma_t / \sigma_T) \tau_r$도 크기 때문에 예측 결과는 $z_{LQ}$에 더 가깝습니다.

확산 예측의 후반 단계에서는 주로 고주파 세부 사항이 생성됩니다. 이때는 너무 많은 제약을 가하지 않아야 세부 사항과 질감이 적절하게 생성될 수 있습니다. 이 시점에서는 $t$와 $\sigma_t$가 비교적 작고, 가중치 $k$도 작습니다. 따라서 예측 결과는 크게 영향을 받지 않습니다. 이 방법을 통해 우리는 확산 샘플링 과정에서 생성을 제어하여 충실도를 보장할 수 있습니다.

# 4. Experiment

## 4.1. Model Training and Sampling Settings

훈련을 위해, 전체 훈련 데이터는 텍스트 설명이 포함된 2천만 개의 고품질 이미지, 7만 개의 얼굴 이미지, 10만 개의 부정적 품질 샘플과 그에 해당하는 프롬프트로 구성됩니다. 더 큰 배치 크기를 가능하게 하기 위해, 우리는 훈련 중에 이미지를 512×512 패치로 자릅니다. 우리는 Real-ESRGAN [81]에서 사용한 설정을 따르며 합성 열화 모델을 사용하여 모델을 훈련시킵니다. 유일한 차이점은 생성된 LQ 이미지를 훈련을 위해 512×512로 리사이즈하는 것입니다. 우리는 학습률이 0.00001인 AdamW 옵티마이저 [54]를 사용합니다. 훈련 과정은 10일이 걸리며 64개의 Nvidia A6000 GPU에서 배치 크기 256으로 수행됩니다.

테스트를 위해, 하이퍼파라미터는 $T=100$, $\lambda_{\text{cfg}}=7.5$, $\tau_r=4$입니다. 우리의 방법은 1024×1024 크기의 이미지를 처리할 수 있습니다. 우리는 입력 이미지의 짧은 쪽을 1024로 리사이즈하고 테스트를 위해 1024×1024 서브 이미지를 자른 후 복원 후 원래 크기로 다시 리사이즈합니다. 특별한 언급이 없는 한, 프롬프트는 수동으로 제공되지 않으며, 처리는 완전히 자동으로 이루어집니다.

## 4.2. Comparison with Existing Methods

우리의 방법은 다양한 열화를 처리할 수 있으며, 동일한 기능을 가진 최신 방법들과 비교됩니다. 여기에는 BSRGAN [93], Real-ESRGAN [81], StableSR [77], DiffBIR [49], PASD [88]가 포함됩니다. 이들 중 일부는 512×512 크기의 이미지만 생성할 수 있습니다. 비교 시, 테스트 이미지를 이 요구 사항에 맞추기 위해 자르고 결과를 다운샘플링합니다. 우리는 합성 데이터와 실제 데이터 모두에서 비교를 수행합니다.

**Synthetic Data.** 테스트를 위해 저품질(LQ) 이미지를 합성하기 위해, 우리는 이전 연구들 [45, 97]을 따르며 여러 대표적인 열화, 단일 열화 및 복잡한 혼합 열화에서의 효과를 보여줍니다. 구체적인 내용은 표 1에 나와 있습니다. 우리는 정량적 비교를 위해 다음과 같은 메트릭을 선택했습니다: 참조 메트릭으로는 PSNR, SSIM, LPIPS [96], 비참조 메트릭으로는 ManIQA [86], ClipIQA [76], MUSIQ [43]를 사용했습니다. 우리의 방법이 모든 비참조 메트릭에서 최고의 결과를 달성하여, 결과의 우수한 이미지 품질을 반영합니다. 동시에, 우리는 참조 메트릭에서 우리의 방법의 단점을 지적합니다. 우리는 이러한 참조 메트릭의 한계를 강조하는 간단한 실험을 제시합니다(그림 7 참조). 우리의 결과가 더 나은 시각적 효과를 제공하지만, 이러한 메트릭에서는 이점을 가지지 않음을 알 수 있습니다. 이 현상은 많은 연구에서도 관찰되었습니다 [6, 26, 28]. 우리는 IR의 품질이 향상됨에 따라 기존 메트릭의 참조 값을 재고하고 고급 IR 방법을 평가하는 더 효과적인 방법을 제안해야 한다고 주장합니다. 우리는 또한 그림 6에서 몇 가지 질적 비교 결과를 보여줍니다. 심각한 열화에서도 우리의 방법은 매우 합리적이고 고품질의 이미지를 일관되게 생성하여 LQ 이미지의 콘텐츠를 충실하게 표현합니다.

### Restoration in the Wild.

우리는 우리의 방법을 실제 저품질(LQ) 이미지에서도 테스트합니다. RealSR [8], DRealSR [83], Real47 [49], 및 온라인 소스에서 총 60개의 실제 LQ 이미지를 수집하였으며, 여기에는 동물, 식물, 얼굴, 건물, 풍경 등 다양한 콘텐츠가 포함되어 있습니다. 그림 10에 질적 결과를, 표 2a에 정량적 결과를 보여줍니다. 이러한 결과는 우리의 방법이 최고 수준의 지각 품질을 가진 이미지를 생성함을 나타냅니다.

또한, 20명의 참가자가 참여한 사용자 연구를 수행하여 우리의 방법을 실제 LQ 이미지에서 다른 최신 방법들과 비교했습니다. 각 비교 이미지 세트에 대해, 참가자들에게 이러한 테스트 방법 중 가장 높은 품질의 복원 결과를 선택하도록 지시했습니다. 결과는 그림 8에 나와 있으며, 우리의 접근 방식이 지각 품질에서 최신 방법들을 크게 능가함을 보여줍니다.

## 4.3. Controlling Restoration with Textual Prompts

대규모 이미지-텍스트 쌍 데이터셋으로 훈련하고 diffusion 모델의 기능을 활용한 후, 우리의 방법은 인간의 프롬프트를 기반으로 이미지를 선택적으로 복원할 수 있습니다. 그림 1(b)는 몇 가지 예를 보여줍니다. 첫 번째 경우에서, 자전거 복원은 프롬프트 없이 어려우나, 프롬프트를 받으면 모델이 정확하게 복원합니다. 두 번째 경우에서는 모자의 재질 질감을 프롬프트를 통해 조정할 수 있습니다. 세 번째 경우에서는 높은 수준의 의미론적 프롬프트를 통해 얼굴 속성의 조작이 가능합니다. 

이미지 콘텐츠 프롬프트 외에도, 우리는 부정적 품질 프롬프트를 통해 모델이 더 높은 품질의 이미지를 생성하도록 유도할 수 있습니다. 그림 11(a)에서는 두 가지 예시를 보여줍니다. 부정적 프롬프트가 출력 이미지의 전체 품질을 개선하는 데 매우 효과적임을 알 수 있습니다. 우리는 또한 프롬프트가 항상 효과적이지 않음을 관찰했습니다. 제공된 프롬프트가 LQ 이미지와 일치하지 않을 때, 프롬프트는 비효과적이 됩니다(그림 11(b) 참조). 우리는 IR 방법이 제공된 LQ 이미지에 충실하도록 유지하는 것이 합리적이라고 생각합니다. 이는 텍스트-이미지 생성 모델과의 중요한 차이점을 반영하며 우리의 접근 방식의 강건함을 강조합니다.

## 4.4. Ablation Study

**Connector.** 우리는 제안된 ZeroSFT 커넥터를 제로 컨볼루션 [95]과 비교합니다. 정량적 결과는 표 2c에 나와 있습니다. ZeroSFT와 비교했을 때, 제로 컨볼루션은 비참조 메트릭에서 비슷한 성능을 보이지만, 참조 메트릭에서는 훨씬 낮은 성능을 보입니다. 그림 9에서, 비참조 메트릭의 하락이 저충실도 콘텐츠 생성으로 인해 발생함을 발견했습니다. 따라서 IR 태스크의 경우, ZeroSFT는 지각 효과를 잃지 않으면서 충실도를 보장합니다.

**Training data scaling.** 우리는 우리의 대규모 모델을 IR을 위한 두 개의 소규모 데이터셋, 즉 DIV2K [3]와 LSDIR [1]에 대해 훈련했습니다. 질적 결과는 그림 12에 나와 있으며, 이는 대규모 고품질 데이터에서 훈련하는 중요성과 필요성을 명확히 보여줍니다.

**Negative-quality samples and prompt.** 표 2b는 다양한 설정에서의 정량적 결과를 보여줍니다. 여기서 우리는 이미지 품질을 설명하는 긍정적 단어를 "positive prompt"로, 부정적 품질 단어와 섹션 3.2에 설명된 CFG 방법을 "negative prompt"로 사용했습니다. 긍정적 프롬프트나 부정적 프롬프트를 추가하는 것만으로도 이미지의 지각 품질을 향상시킬 수 있음을 알 수 있습니다. 두 가지를 동시에 사용하는 것이 최고의 지각 결과를 가져옵니다. 훈련에 부정적 샘플이 포함되지 않은 경우, 이 두 프롬프트는 지각 품질을 향상시킬 수 없습니다. 그림 4와 그림 11(a)는 부정적 프롬프트를 사용하여 이미지 품질이 향상되는 것을 보여줍니다.

**Restoration-guided sampling method.** 제안된 복원 유도 샘플링 방법은 주로 $\tau_r$에 의해 제어됩니다. $\tau_r$가 클수록 각 단계에서 생성에 대한 수정이 적게 이루어집니다. $\tau_r$가 작을수록 생성된 콘텐츠는 각 확산 단계에서 LQ 이미지에 더 가깝게 강제됩니다. 질적 비교를 위해 그림 13을 참조하십시오. $\tau_r = 0.5$일 때, 이미지가 흐릿해지는데, 이는 출력이 LQ 이미지에 제한되어 질감과 디테일을 생성할 수 없기 때문입니다. $\tau_r = 6$일 때, 생성 중에 많은 지침이 없어 모델이 LQ 이미지에 없는 많은 질감을 생성합니다, 특히 평평한 영역에서 그렇습니다. 그림 8(a)는 변수 $\tau_r$의 함수로서 복원의 정량적 결과를 보여줍니다. 그림 8(a)에서 볼 수 있듯이, $\tau_r$를 6에서 4로 줄이는 것은 시각적 품질에서 큰 하락을 초래하지 않으며, 충실도 성능이 향상됩니다. 복원 지침이 강화됨에 따라, PSNR이 계속해서 향상됨에도 불구하고, 이미지가 점차 디테일을 잃으면서 흐릿해집니다(그림 13 참조). 따라서, 우리는 $\tau_r = 4$를 기본 매개변수로 선택했으며, 이는 이미지 품질을 타협하지 않으면서도 충실도를 효과적으로 향상시킵니다.