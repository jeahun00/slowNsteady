# Abstract

Convolutional Neural Networks (CNNs)는 대규모 데이터로부터 일반화 가능한 이미지 사전(image priors)을 학습하는 데 뛰어난 성능을 보이기 때문에 이미지 복원 및 관련 작업에 널리 적용되어 왔습니다. 최근에는 Transformer라는 또 다른 유형의 신경망 구조가 자연어 및 고수준 비전 작업에서 상당한 성능 향상을 보여주고 있습니다. Transformer 모델은 CNN의 한계(즉, 제한된 수용 영역 및 입력 콘텐츠에 대한 비적응성)를 완화하지만, 공간 해상도와 함께 계산 복잡성이 제곱으로 증가하여 고해상도 이미지를 포함하는 대부분의 이미지 복원 작업에 적용하기 어렵게 만듭니다. 본 연구에서는 여러 핵심 디자인(다중 헤드 주의 및 피드 포워드 네트워크)을 통해 효율적인 Transformer 모델을 제안하여, 긴 거리의 픽셀 상호작용을 캡처하면서도 대형 이미지에 적용할 수 있도록 하였습니다. 본 모델인 Restoration Transformer(Restoremer)는 이미지 제거, 단일 이미지 모션 디블러링, 디포커스 디블러링(단일 이미지 및 듀얼 픽셀 데이터), 이미지 디노이징(가우시안 그레이스케일/컬러 디노이징 및 실제 이미지 디노이징) 등 여러 이미지 복원 작업에서 최신 성능을 달성하였습니다. 소스 코드와 사전 학습된 모델은 https://github.com/swz30/Restormer에서 제공됩니다.

# Introduction

이미지 복원은 저하된 입력 이미지에서 노이즈, 블러, 빗방울 등의 열화를 제거하여 고품질 이미지를 재구성하는 작업입니다. 이 작업은 본질적으로 잘못된 문제이기 때문에 효과적인 복원을 위해서는 강력한 이미지 사전이 필요합니다. Convolutional Neural Networks (CNNs)는 대규모 데이터로부터 일반화 가능한 사전을 학습하는 데 뛰어난 성능을 보이기 때문에 기존의 복원 접근법에 비해 선호되는 선택으로 부상했습니다.

CNN의 기본 연산은 '컨볼루션'으로, 이는 지역 연결성과 이동 불변성을 제공합니다. 이러한 특성은 CNN에 효율성과 일반화를 가져다주지만, 두 가지 주요 문제를 야기합니다. (a) 컨볼루션 연산자는 제한된 수용 영역을 가지므로 장거리 픽셀 종속성을 모델링하는 것을 방해합니다. (b) 컨볼루션 필터는 추론 시 정적인 가중치를 가지므로 입력 콘텐츠에 유연하게 적응할 수 없습니다. 위에서 언급한 단점을 해결하기 위해 보다 강력하고 동적인 대안은 self-attention (SA) 메커니즘입니다. SA 메커니즘은 주어진 픽셀에서 모든 다른 위치의 가중 합을 계산하여 응답을 산출합니다.

Self-attention은 Transformer 모델의 핵심 구성 요소입니다. 특히 병렬화와 효율적인 표현 학습을 위해 최적화된 multi-head self-attention (SA) 구현이 특징입니다. Transformers는 자연어 처리 작업 및 고수준 비전 문제에서 최첨단 성능을 보여주었습니다. 비록 SA가 장거리 픽셀 상호작용을 포착하는 데 매우 효과적이지만, 공간 해상도가 높아짐에 따라 복잡성이 제곱으로 증가하여 고해상도 이미지(이미지 복원에서 흔히 발생하는 경우)에는 적용하기 어렵습니다. 최근에는 이미지를 복원하는 작업을 위해 Transformers를 조정하려는 몇 가지 시도가 있었습니다. 이러한 방법들은 계산 부담을 줄이기 위해 작은 8×8 크기의 공간 윈도우에서 SA를 적용하거나 입력 이미지를 48×48 크기의 비중첩 패치로 나누어 각 패치에서 독립적으로 SA를 계산합니다. 그러나 SA의 공간 범위를 제한하는 것은 특히 고해상도 이미지에서 실제 장거리 픽셀 관계를 포착하는 목표와 상충됩니다.

본 논문에서는 글로벌 연결성을 모델링할 수 있으면서도 대형 이미지에 적용 가능한 효율적인 Transformer를 제안합니다. 구체적으로, 우리는 기존의 multi-head SA 대신 선형 복잡도를 가진 multi-Dconv head ‘transposed’ attention (MDTA) 블록을 도입합니다. 이는 공간 차원 대신 특징 차원에서 SA를 적용하여, 개별 픽셀 상호작용을 명시적으로 모델링하는 대신, 특징 채널 간 교차 공분산을 계산하여 (key와 query로 투영된) 입력 특징에서 주의(attention) 맵을 얻습니다. ==MDTA 블록의 중요한 특징은 특징 공분산 계산 전에 지역적 문맥 혼합(local context mixing)입니다. 이는 1×1 컨볼루션을 사용한 교차 채널 문맥의 픽셀 단위 집계 및 효율적인 depth-wise 컨볼루션을 사용한 지역 문맥의 채널 단위 집계를 통해 달성됩니다. 이 전략은 두 가지 주요 이점을 제공합니다. 첫째, 공간적으로 지역적인 문맥을 강조하여 파이프라인 내에서 컨볼루션 연산의 보완적 강점을 가져옵니다. 둘째, 공분산 기반 주의 맵을 계산하는 동안 픽셀 간 문맥화된 글로벌 관계가 암묵적으로 모델링되도록 보장합니다.==
**--> 나중에 이해해 볼 것**

Feed-forward network (FN)은 Transformer 모델의 또 다른 구성 요소로, 두 개의 완전 연결 층과 그 사이에 비선형성을 포함합니다. 본 연구에서는 네트워크를 통한 정보 흐름을 개선하기 위해 기존 FN의 첫 번째 선형 변환 층을 gating 메커니즘으로 재구성하였습니다. 이 gating 층은 두 개의 선형 투영 층의 원소별 곱으로 설계되었으며, 그 중 하나는 GELU 비선형성으로 활성화됩니다. 우리의 gated-Dconv FN (GDFN)은 MDTA 모듈과 유사하게 지역적 문맥 혼합에 기반하여 공간적 문맥을 동일하게 강조합니다. GDFN의 gating 메커니즘은 어떤 보완적인 특징이 앞으로 전달되어야 하는지를 제어하여 네트워크 계층의 후속 층들이 더 정교한 이미지 속성에 집중할 수 있게 합니다. 이는 고품질 출력으로 이어집니다.

위의 건축적 혁신 외에도, 우리는 Restormer의 점진적 학습 전략의 효과를 보여줍니다. 이 과정에서 네트워크는 초기 에포크에서 작은 패치와 큰 배치로, 이후 에포크에서는 점진적으로 큰 이미지 패치와 작은 배치로 학습됩니다. 이러한 학습 전략은 Restormer가 큰 이미지로부터 문맥을 학습하게 하여, 테스트 시 성능 향상을 제공합니다. 우리는 포괄적인 실험을 수행하여 이미지 제거, 단일 이미지 모션 디블러링, 디포커스 디블러링(단일 이미지 및 듀얼 픽셀 데이터), 이미지 디노이징(합성 및 실제 데이터) 등 여러 이미지 복원 작업에 대해 16개의 벤치마크 데이터셋에서 Restormer의 최신 성능을 입증합니다. 또한 건축적 디자인과 실험적 선택의 효과를 보여주기 위해 광범위한 ablation 실험을 제공합니다.

본 연구의 주요 기여는 다음과 같이 요약됩니다:
- 우리는 고해상도 이미지에서 지역 윈도우로 분해하지 않고 멀티스케일 지역-글로벌 표현 학습을 위한 encoder-decoder Transformer인 Restormer를 제안합니다.
- 우리는 지역 및 비지역 픽셀 상호작용을 집계할 수 있으며, 고해상도 이미지를 처리하기에 충분히 효율적인 multi-Dconv head transposed attention (MDTA) 모듈을 제안합니다.
- 정보량이 적은 특징을 억제하고 유용한 정보만 네트워크 계층을 통해 전달하는 제어된 특징 변환을 수행하는 새로운 gated-Dconv feed-forward network (GDFN)를 제안합니다.

# 2. 배경

## Image Restoration

최근 몇 년간, 데이터 기반의 CNN 구조가 기존의 복원 접근 방식을 능가하는 것으로 나타났습니다. 특히, encoder-decoder 기반의 U-Net 아키텍처는 계층적 멀티스케일 표현을 제공하면서도 계산 효율성을 유지하여 복원 작업에 주로 연구되었습니다. 이와 유사하게, 잔여 신호 학습에 특정한 집중을 하는 skip connection 기반 접근법도 복원에 효과적인 것으로 입증되었습니다. 또한, 공간 및 채널 주의 모듈이 관련 정보에 선택적으로 집중하기 위해 통합되었습니다. 주요 디자인 선택을 요약한 NTIRE 챌린지 보고서와 최근 문헌 리뷰를 참조하십시오.

## Vision Transformers

Transformer 모델은 처음에 자연어 작업에서 시퀀스 처리를 위해 개발되었습니다. 이는 이미지 인식, 분할, 객체 탐지와 같은 다양한 비전 작업에 적용되었습니다. 비전 Transformers는 이미지를 패치(지역 윈도우)의 시퀀스로 분해하고 이들 간의 상호 관계를 학습합니다. 이러한 모델의 특징은 이미지 패치 시퀀스 간의 장거리 종속성을 학습하는 강력한 능력과 주어진 입력 콘텐츠에 대한 적응성입니다. 이러한 특성으로 인해 Transformer 모델은 초해상도, 이미지 색채화, 디노이징, 및 디레이닝과 같은 저수준 비전 문제에도 연구되었습니다. 그러나 Transformers에서 SA의 계산 복잡성은 이미지 패치 수에 따라 제곱으로 증가할 수 있어 고해상도 이미지에 적용하기 어렵습니다. 따라서 고해상도 출력을 생성해야 하는 저수준 이미지 처리 애플리케이션에서는 일반적으로 복잡성을 줄이기 위한 다양한 전략이 사용됩니다. 하나의 잠재적인 해결책은 Swin Transformer 설계를 사용하여 지역 이미지 영역 내에서 self-attention을 적용하는 것입니다. 그러나 이 설계 선택은 지역 이웃 내에서 문맥 집계를 제한하여 컨볼루션 대신 self-attention을 사용하는 주요 동기를 무색하게 만들며, 이미지 복원 작업에 이상적이지 않습니다. 반면에, 우리는 장거리 종속성을 학습하면서도 계산 효율성을 유지할 수 있는 Transformer 모델을 제시합니다.

# 3. Method

우리의 주요 목표는 복원 작업을 위해 고해상도 이미지를 처리할 수 있는 효율적인 Transformer 모델을 개발하는 것입니다. 계산 병목 현상을 완화하기 위해 multi-head self-attention (SA) 레이어와 단일 스케일 네트워크보다 더 적은 계산 요구 사항을 가진 멀티 스케일 계층 모듈에 주요 설계를 도입합니다. 먼저 Restormer 아키텍처의 전체 파이프라인을 소개한 후, 제안된 Transformer 블록의 핵심 구성 요소를 설명합니다: (a) multi-Dconv head transposed attention (MDTA) 및 (b) gated-Dconv feed-forward network (GDFN). 마지막으로 이미지 통계를 효과적으로 학습하기 위한 점진적 학습 계획에 대한 세부 사항을 제공합니다.

### Overview Pipeline

저하된 이미지 $\mathbf{I} \in \mathbb{R}^{H \times W \times 3}$가 주어지면, Restormer는 먼저 컨볼루션을 적용하여 저수준 특징 임베딩 $\mathbf{F}_0 \in \mathbb{R}^{H \times W \times C}$을 얻습니다. 여기서 $H \times W$는 공간 차원을 나타내고 $C$는 채널 수입니다. 다음으로, 이러한 얕은 특징 $\mathbf{F}_0$는 4단계 대칭 인코더-디코더를 거쳐 깊은 특징 $\mathbf{F}_d \in \mathbb{R}^{H \times W \times 2C}$으로 변환됩니다. 인코더-디코더의 각 단계는 여러 Transformer 블록을 포함하며, 블록의 수는 효율성을 유지하기 위해 상위 단계에서 하위 단계로 갈수록 점진적으로 증가합니다. 고해상도 입력에서 시작하여 인코더는 공간 크기를 계층적으로 줄이면서 채널 용량을 확장합니다. 디코더는 저해상도 잠재 특징 $\mathbf{F}_l \in \mathbb{R}^{\frac{H}{8} \times \frac{W}{8} \times 8C}$을 입력으로 받아 고해상도 표현을 점진적으로 복원합니다.

특징 다운샘플링 및 업샘플링을 위해 우리는 각각 pixel-unshuffle 및 pixel-shuffle 연산을 적용합니다. 복구 과정을 지원하기 위해 인코더 특징은 skip connections을 통해 디코더 특징과 연결됩니다. 연결 작업 후에는 모든 레벨(상위 하나 제외)에서 채널을 절반으로 줄이기 위해 1×1 컨볼루션이 뒤따릅니다. 1단계에서는 Transformer 블록이 인코더의 저수준 이미지 특징과 디코더의 고수준 특징을 집계하도록 합니다. 이는 복원된 이미지에서 구조적 및 텍스처 세부 사항을 보존하는 데 유익합니다. 다음으로, 깊은 특징 $\mathbf{F}_d$는 고해상도에서 작동하는 정밀화 단계에서 더욱 풍부해집니다. 이러한 디자인 선택은 품질 향상을 가져오며, 이는 실험 섹션에서 확인할 수 있습니다.

마지막으로, 컨볼루션 레이어가 정제된 특징에 적용되어 잔여 이미지 $\mathbf{R} \in \mathbb{R}^{H \times W \times 3}$를 생성하며, 이는 저하된 이미지에 추가되어 복원된 이미지 $\hat{\mathbf{I}} = \mathbf{I} + \mathbf{R}$를 얻습니다. 다음으로, Transformer 블록의 모듈을 소개합니다.

## 3.1. Multi-Dconv Head Transposed Attention

Transformer에서 주요 계산 오버헤드는 self-attention 레이어에서 발생합니다. 기존의 self-attention (SA)에서는 key-query dot-product 상호작용의 시간 및 메모리 복잡성이 입력의 공간 해상도와 함께 제곱으로 증가합니다. 즉, $W \times H$ 픽셀 이미지의 경우, $O(W^2H^2)$의 복잡성을 가집니다. 따라서 고해상도 이미지를 자주 포함하는 대부분의 이미지 복원 작업에 SA를 적용하는 것은 실현 불가능합니다. 

이 문제를 완화하기 위해 우리는 선형 복잡성을 가지는 MDTA를 제안합니다. Fig. 2(a)에 표시된 바와 같이, 주요 요소는 공간 차원이 아니라 채널에 걸쳐 SA를 적용하는 것입니다. 즉, 채널 간 교차 공분산을 계산하여 글로벌 문맥을 암묵적으로 인코딩하는 attention 맵을 생성합니다. MDTA의 또 다른 필수 구성 요소로서, 특징 공분산을 계산하기 전에 지역 문맥을 강조하기 위해 depth-wise 컨볼루션을 도입하여 글로벌 attention 맵을 생성합니다.

계층 정규화된 텐서 $\mathbf{Y} \in \mathbb{R}^{\hat{H} \times \hat{W} \times \hat{C}}$로부터, 우리의 MDTA는 먼저 query (Q), key (K) 및 value (V) 투영을 생성하며, 이는 지역 문맥으로 강화됩니다. 이는 1×1 컨볼루션을 적용하여 픽셀 단위 교차 채널 문맥을 집계한 후 3×3 depth-wise 컨볼루션을 적용하여 채널 단위 공간 문맥을 인코딩함으로써 달성됩니다. 결과적으로 다음과 같이 됩니다:

$$
\mathbf{Q} = W_d^Q W_p^Q \mathbf{Y}, \quad \mathbf{K} = W_d^K W_p^K \mathbf{Y}, \quad \mathbf{V} = W_d^V W_p^V \mathbf{Y}
$$

여기서 $W_p^{(\cdot)}$는 1×1 포인트-와이즈 컨볼루션이고 $W_d^{(\cdot)}$는 3×3 depth-wise 컨볼루션입니다. 네트워크에서는 바이어스가 없는 컨볼루션 층을 사용합니다. 다음으로 query와 key 투영을 재형성하여 그들의 dot-product 상호작용이 거대한 일반 attention 맵 $\mathbb{R}^{\hat{H} \hat{W} \times \hat{H} \hat{W}}$ 대신에 transposed-attention 맵 $\mathbb{R}^{\hat{C} \times \hat{C}}$를 생성하도록 합니다. 전반적인 MDTA 프로세스는 다음과 같이 정의됩니다:

$$
\hat{\mathbf{X}} = W_p \text{Attention}(\hat{\mathbf{Q}}, \hat{\mathbf{K}}, \hat{\mathbf{V}}) + \mathbf{X},
$$

$$
\text{Attention}(\hat{\mathbf{Q}}, \hat{\mathbf{K}}, \hat{\mathbf{V}}) = \hat{\mathbf{V}} \cdot \text{Softmax}\left(\frac{\hat{\mathbf{K}} \cdot \hat{\mathbf{Q}}}{\alpha}\right),
$$

여기서 $\mathbf{X}$와 $\hat{\mathbf{X}}$는 입력 및 출력 특징 맵이며, $\hat{\mathbf{Q}} \in \mathbb{R}^{\hat{H} \hat{W} \times \hat{C}}$, $\hat{\mathbf{K}} \in \mathbb{R}^{\hat{C} \times \hat{H} \hat{W}}$, $\hat{\mathbf{V}} \in \mathbb{R}^{\hat{H} \hat{W} \times \hat{C}}$ 행렬은 원래 크기 $\mathbb{R}^{\hat{H} \times \hat{W} \times \hat{C}}$에서 텐서를 재형성하여 얻어집니다. 여기서 $\alpha$는 소프트맥스 함수를 적용하기 전에 $\hat{\mathbf{K}}$와 $\hat{\mathbf{Q}}$의 dot-product 크기를 제어하는 학습 가능한 스케일링 파라미터입니다. 기존의 multi-head SA와 유사하게, 우리는 채널 수를 'heads'로 나누고 병렬로 별도의 attention 맵을 학습합니다.

## 3.2. Gated-Dconv Feed-Forward Network

특징을 변환하기 위해, 기존의 feed-forward network (FN)은 각 픽셀 위치에서 별도로 동일하게 작동합니다. 이는 두 개의 1×1 컨볼루션을 사용하며, 하나는 특징 채널을 확장(보통 계수 $\gamma=4$)하고, 다른 하나는 채널을 원래 입력 차원으로 다시 줄입니다. 숨겨진 층에서는 비선형성이 적용됩니다. 본 연구에서는 표현 학습을 개선하기 위해 FN에 두 가지 기본적인 수정을 제안합니다: (1) gating 메커니즘, (2) depthwise 컨볼루션. 우리의 GDFN 아키텍처는 Fig. 2(b)에 나타나 있습니다. gating 메커니즘은 두 개의 평행한 선형 변환 경로의 원소별 곱으로 형성되며, 그 중 하나는 GELU 비선형성으로 활성화됩니다. MDTA와 마찬가지로, GDFN에서도 지역 이미지 구조를 학습하는 데 유용한 공간적으로 인접한 픽셀 위치로부터 정보를 인코딩하기 위해 depth-wise 컨볼루션을 포함합니다.

입력 텐서 $\mathbf{X} \in \mathbb{R}^{\hat{H} \times \hat{W} \times \hat{C}}$가 주어지면, GDFN은 다음과 같이 공식화됩니다:

$$
\hat{\mathbf{X}} = W_p^0 \text{Gating}(\mathbf{X}) + \mathbf{X},
$$

$$
\text{Gating}(\mathbf{X}) = \phi(W_d^1 W_p^1 (\text{LN}(\mathbf{X}))) \odot W_d^2 W_p^2 (\text{LN}(\mathbf{X})),
$$

여기서 $\odot$는 원소별 곱셈을 나타내며, $\phi$는 GELU 비선형성을, LN은 계층 정규화를 나타냅니다. GDFN은 파이프라인 내에서 각각의 계층 수준을 통해 정보 흐름을 제어하여 각 수준이 다른 수준을 보완하면서 세부 사항에 집중할 수 있게 합니다. 즉, GDFN은 MDTA와 비교하여 구별되는 역할을 제공하며(문맥 정보로 특징을 풍부하게 하는 데 중점을 둠), 제안된 GDFN은 더 많은 연산을 수행하므로 확장 비율 $\gamma$를 줄여 유사한 파라미터와 계산 부담을 가지도록 합니다.

## 3.3. Progressive Learning

CNN 기반 복원 모델은 일반적으로 고정 크기의 이미지 패치로 학습됩니다. 그러나 작은 크기의 패치로 Transformer 모델을 학습하면 전체 이미지 통계를 인코딩하지 못해 테스트 시 전체 해상도 이미지에서 최적 이하의 성능을 제공할 수 있습니다. 이를 해결하기 위해 우리는 점진적 학습을 수행합니다. 초기 에포크에서는 작은 이미지 패치로 네트워크를 학습시키고, 이후 에포크에서는 점진적으로 큰 패치로 학습시킵니다. 점진적 학습을 통해 혼합된 크기의 패치로 학습된 모델은 다양한 해상도의 이미지가 있을 때 테스트 시 향상된 성능을 보입니다(이미지 복원에서 일반적인 경우).

점진적 학습 전략은 더 단순한 작업으로 시작하여 점차 더 복잡한 작업을 학습하는 커리큘럼 학습 과정과 유사하게 작동합니다(미세한 이미지 구조/텍스처의 보존이 필요한 경우). 큰 패치로 학습하는 것은 더 많은 시간이 소요되므로, 고정 크기 패치 학습의 최적화 단계와 유사한 시간을 유지하기 위해 패치 크기가 증가함에 따라 배치 크기를 줄입니다.

# 4. 실험 및 분석

제안된 Restormer를 여러 벤치마크 데이터셋과 실험 설정에서 네 가지 이미지 처리 작업에 대해 평가합니다: (a) 이미지 제거, (b) 단일 이미지 모션 디블러링, (c) 디포커스 디블러링(단일 이미지 및 듀얼 픽셀 데이터), (d) 이미지 디노이징(합성 및 실제 데이터). 데이터셋, 학습 프로토콜 및 추가 시각적 결과에 대한 자세한 내용은 보충 자료에 제시되어 있습니다. 표에서는 평가된 방법의 최고 및 차선의 품질 점수를 **굵게** 및 _밑줄_로 강조합니다.

### 구현 세부사항

각 이미지 복원 작업에 대해 별도의 모델을 학습합니다. 모든 실험에서 별도로 언급하지 않는 한 다음 학습 매개변수를 사용합니다. 우리의 Restormer는 4단계 인코더-디코더를 사용합니다.

레벨 1부터 레벨 4까지, Transformer 블록의 수는 [4, 6, 6, 8]이고, MDTA의 어텐션 헤드 수는 [1, 2, 4, 8]이며, 채널 수는 [48, 96, 192, 384]입니다. 정제 단계는 4개의 블록을 포함합니다. GDFN의 채널 확장 계수는 $\gamma=2.66$입니다. AdamW 옵티마이저 ($\beta_1=0.9$, $\beta_2=0.999$), weight decay $1e^{-4}$ 및 $L_1$ 손실 함수를 사용하여 초기 학습률 $3e^{-4}$로 300K 반복 동안 모델을 학습하고, 코사인 에닐링을 통해 $1e^{-6}$로 점진적으로 감소시킵니다. 점진적 학습을 위해 패치 크기 $128 \times 128$에서 학습을 시작합니다.

패치 크기와 배치 크기 쌍은 다음과 같이 업데이트됩니다: $(160^2, 40)$, $(192^2, 32)$, $(256^2, 16)$, $(320^2, 8)$, $(384^2, 8)$에서 각 반복 [92K, 156K, 204K, 240K, 276K]. 데이터 증강을 위해 수평 및 수직 플립을 사용합니다.

## 4.1. 이미지 제거 결과

YCbCr 색상 공간에서 Y 채널을 사용하여 PSNR/SSIM 점수를 기존 방법과 유사하게 계산합니다. Table 1은 우리의 Restormer가 모든 다섯 개의 데이터셋에서 기존 접근법보다 일관되고 상당한 성능 향상을 달성했음을 보여줍니다. 최근의 최적 방법인 SPAIR과 비교하여, Restormer는 모든 데이터셋에서 평균 1.05 dB의 개선을 달성했습니다. 개별 데이터셋에서는 최대 2.06 dB의 향상을 보였으며, 예를 들어 Rain100L 데이터셋에서 그렇습니다. Figure 3은 도전적인 시각적 예제를 보여줍니다. 우리의 Restormer는 구조적 콘텐츠를 효과적으로 보존하면서 빗방울이 없는 이미지를 재현합니다.

## 4.2. 단일 이미지 모션 디블러링 결과

우리는 합성 데이터셋(GoPro, HIDE)과 실제 세계 데이터셋(RealBlur-R, RealBlur-J) 모두에서 디블러링 방법을 평가합니다. Table 2는 우리의 Restormer가 모든 네 개의 벤치마크 데이터셋에서 다른 접근법보다 뛰어남을 보여줍니다. 모든 데이터셋에서 평균적으로, 우리의 방법은 최근 알고리즘 MIMO-UNet+보다 0.47 dB, 이전 최적 방법인 MPRNet보다 0.26 dB의 성능 향상을 얻었습니다. MPRNet과 비교하여, Restormer는 81% 적은 FLOPs를 가집니다.

또한, 우리의 방법은 Transformer 모델 IPT보다 0.4 dB의 성능 향상을 보이며, 매개변수는 4.4배 적고, 속도는 29배 빠릅니다. 주목할 만하게도, 우리의 Restormer는 오직 GoPro 데이터셋에서만 학습되었지만, 다른 데이터셋에 대한 강력한 일반화를 보여주며 새로운 최첨단 성능을 설정합니다. Fig. 4는 우리의 방법으로 생성된 이미지가 다른 알고리즘보다 더 선명하고 시각적으로 실제 이미지에 더 가깝다는 것을 보여줍니다.

## 4.3. 디포커스 디블러링 결과

Table 3은 기존의 디포커스 디블러링 방법(EBDB 및 JNB)뿐만 아니라 DPDD 데이터셋에서 학습 기반 접근법의 이미지 충실도 점수를 보여줍니다. 우리의 Restormer는 단일 이미지 및 듀얼 픽셀 디포커스 디블러링 작업에서 모든 장면 범주에 대해 최신 방법들을 능가합니다. 특히 결합된 장면 범주에서는 이전 최적 방법인 IFAN보다 약 0.6 dB의 개선을 달성했습니다. Transformer 모델 Uformer와 비교했을 때, 우리의 방법은 PSNR에서 1.01 dB의 상당한 향상을 제공합니다. Figure 5는 우리의 방법이 다른 접근법보다 공간적으로 다양한 디포커스 블러를 제거하는 데 더 효과적임을 보여줍니다.

## 4.4. 이미지 디노이징 결과

우리는 합성 벤치마크 데이터셋(Set12, BSD68, Urban100, Kodak24, McMaster)과 실제 세계 데이터셋(SIDD 및 DND)에서 가우시안 노이즈가 추가된 상태로 디노이징 실험을 수행합니다. 기존 방법과 일치하게 우리는 편향이 없는 Restormer를 디노이징에 사용합니다.

#### 가우시안 디노이징

Table 4와 Table 5는 그레이스케일 및 컬러 이미지 디노이징에 대한 여러 벤치마크 데이터셋에서 다양한 접근법의 PSNR 점수를 보여줍니다. 기존 방법과 일치하게 우리는 테스트에서 노이즈 레벨 15, 25 및 50을 포함합니다. 평가된 방법은 두 가지 실험 범주로 나뉩니다: (1) 다양한 노이즈 레벨을 처리하기 위한 단일 모델 학습, (2) 각 노이즈 레벨에 대해 별도의 모델 학습. 우리의 Restormer는 다양한 데이터셋과 노이즈 레벨에 대해 두 가지 실험 설정 모두에서 최첨단 성능을 달성합니다. 특히, 고해상도 Urban100 데이터셋에서의 노이즈 레벨 50의 경우, Restormer는 이전 최적 CNN 기반 방법인 DRUNet보다 0.37 dB, 최근 Transformer 기반 네트워크 SwinIR보다 0.31 dB 성능 향상을 달성합니다. 유사한 성능 향상은 Table 5에서 가우시안 컬러 디노이징에서도 관찰할 수 있습니다. DRUNet이 추가 입력으로 노이즈 레벨 맵을 필요로 하는 반면, 우리의 방법은 노이즈 이미지 만을 입력으로 사용합니다. 또한, SwinIR과 비교했을 때, 우리의 Restormer는 3.14배 적은 FLOPs를 가지며 13배 더 빠르게 실행됩니다. Figure 6은 그레이스케일 디노이징(상단 행)과 컬러 디노이징(중간 행)에 대한 다양한 방법의 디노이징 결과를 보여줍니다. 우리의 Restormer는 깨끗하고 선명한 이미지를 복원합니다.

#### 실제 이미지 디노이징

Table 6은 SIDD 및 DND 데이터셋 모두에서 40 dB PSNR을 초과하는 유일한 방법임을 보여줍니다. 특히 SIDD 데이터셋에서 우리의 Restormer는 이전 최적 CNN 방법인 MIRNet 및 Transformer 모델 Uformer보다 각각 0.3 dB 및 0.25 dB PSNR 향상을 얻습니다. Figure 6(하단 행)은 우리의 Restormer가 세부 텍스처를 손상시키지 않으면서 깨끗한 이미지를 생성함을 보여줍니다.

## 4.5. Ablation 연구

Ablation 실험을 위해, 우리는 100K 반복 동안 128×128 크기의 이미지 패치에서 가우시안 컬러 디노이징 모델을 학습합니다. 테스트는 Urban100 데이터셋에서 노이즈 레벨 $\sigma=50$에서 수행되며, 분석은 256×256 크기의 이미지에서 FLOPs 및 추론 시간을 계산하여 제공됩니다. Table 7-10은 우리의 기여가 질적 성능 향상을 가져옴을 보여줍니다. 다음으로 각 구성 요소의 영향을 개별적으로 설명합니다.

#### multi-head attention의 개선

Table 7c는 우리의 MDTA가 기준선 대비 0.32 dB의 유리한 이득을 제공함을 보여줍니다(Table 7a 참조). 또한 depth-wise 컨볼루션을 통해 MDTA에 지역성을 도입하면, 이를 제거할 경우 PSNR이 감소하는 것으로 나타나 MDTA의 강건성이 향상됩니다(Table 7b 참조).

#### feed-forward network (FN)의 개선

Table 7d는 FN에서 정보 흐름을 제어하기 위한 게이팅 메커니즘이 기존 FN 대비 0.12 dB의 이득을 제공함을 보여줍니다. multi-head attention과 마찬가지로, FN에 로컬 메커니즘을 도입하면 성능 이점이 있습니다(Table 7e 참조). 우리는 gated depth-wise 컨볼루션을 통합하여 FN을 더욱 강화합니다. 우리의 GDFN은 노이즈 레벨 50에서 표준 FN 대비 0.26 dB의 PSNR 이득을 달성합니다(Table 7f 참조). 전반적으로, 우리의 Transformer 블록 기여는 기준선 대비 0.51 dB의 유의미한 이득을 가져옵니다.

#### 레벨 1의 디코더를 위한 설계 선택

레벨 1에서 인코더 특징과 디코더를 집계하기 위해, 우리는 연결 작업 후 채널을 절반으로 줄이는 1×1 컨볼루션을 사용하지 않습니다. 이는 인코더에서 오는 미세한 텍스처 세부 정보를 보존하는 데 유용합니다(Table 8 참조). 이러한 결과는 정제 단계에서 Transformer 블록을 추가하는 것이 효과적임을 추가로 입증합니다.

#### 점진적 학습의 영향

Table 9는 점진적 학습이 고정 패치 학습보다 더 나은 결과를 제공하면서도 유사한 학습 시간을 가지는 것을 보여줍니다.

#### 더 깊은 Restormer 또는 더 넓은 Restormer?

Table 10은 유사한 매개변수/FLOPs 예산 하에서 깊고 좁은 모델이 넓고 얕은 모델보다 더 정확하게 작동함을 보여줍니다. 그러나 넓은 모델은 병렬화 덕분에 더 빠르게 실행됩니다. 본 논문에서는 깊고 좁은 Restormer를 사용합니다.