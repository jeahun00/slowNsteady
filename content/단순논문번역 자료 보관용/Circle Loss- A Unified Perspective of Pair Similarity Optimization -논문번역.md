# Abstract

이 논문은 딥 피처 학습에 관한 쌍 유사도 최적화 관점을 제시하며, **동일 class 내 유사도 $s_p$를 최대화**하고 **서로 다른 class 간 유사도 $s_n$를 최소화**하는 것을 목표로 한다.
저자들은 triplet loss(triplet loss)과 softmax cross-entropy loss(softmax cross-entropy loss)을 비롯한 <mark style='background:var(--mk-color-orange)'>대다수의 loss 함수</mark>들이 $s_n$과 $s_p$를 유사도 쌍에 포함시켜 $s_n - s_p$를 줄이는 방향으로 최적화를 시도한다는 것을 발견했다. 
그러나 이와 같은 최적화 방식은 모든 개별 유사도 점수에 동일한 페널티가 부과되므로 유연성이 떨어진다. 저자들의 직관에 따르면, 유사도 점수가 최적점에서 멀리 벗어나 있을 경우 강조해야 한다. 이를 위해 저자들은 간단히 각 유사도에 가중치를 다시 부여해 덜 최적화된 유사도 점수를 강조했다. 이를 통해 원형 decision boundary로 인해 이름 붙여진 Circle loss가 탄생했다. Circle loss는 class 수준 레이블과 쌍별 레이블의 두 가지 기본적인 딥 피처 학습 패러다임에 대해 통일된 공식을 가지고 있다. 분석적으로, 저자들은 Circle loss가 $s_n - s_p$를 최적화하는 loss 함수에 비해 보다 명확한 수렴 목표를 향한 유연한 최적화 접근법을 제공한다는 것을 보여준다. 실험적으로는, Circle loss가 다양한 딥 피처 학습 작업에서 뛰어남을 입증했다. 얼굴 인식, 인물 재식별(person re-identification) 및 여러 세밀한 이미지 검색 데이터셋에서의 성과는 최신 기술과 동등한 수준에 도달했다.


# 1. Introduction

이 논문은 두 가지 기본적인 딥 피처 학습 패러다임에 대한 유사도 최적화 관점을 제시한다. 즉, class 수준 레이블이 있는 데이터로부터 학습하는 것과 쌍별 레이블이 있는 데이터로부터 학습하는 것이다. 전자는 분류 loss 함수(e.g., softmax cross-entropy loss [25, 16, 36])를 사용하여 샘플과 가중치 벡터 간의 유사도를 최적화하고, 후자는 메트릭 loss 함수(e.g., triplet loss [9, 22])를 활용하여 샘플 간 유사도를 최적화한다.

저자들의 해석에 따르면, 이 두 가지 학습 접근 방식 사이에는 본질적인 차이가 없다. 두 방식 모두 서로 다른 class 간 유사도 $s_n$을 최소화하고 동일 class 내 유사도 $s_p$를 최대화하려고 한다. 이러한 관점에서 보았을 때, triplet loss [9, 22], softmax cross-entropy loss 및 그 변형들 [25, 16, 36, 29, 32, 2]과 같은 많은 인기 있는 loss 함수들이 유사한 최적화 패턴을 공유하고 있다는 사실을 발견했다. 이들은 모두 $s_n$과 $s_p$를 유사도 쌍에 포함시켜 $s_n - s_p$를 줄이려고 한다. 여기서 $s_p$를 증가시키는 것은 $s_n$을 줄이는 것과 동등하다.

저자들은 이러한 대칭적 최적화 방식이 다음 두 가지 문제에 취약하다고 주장한다.
### Lack of flexibility for optimization:
$s_n$과 $s_p$에 대한 패널티 강도가 동일하게 제한되어 있다. 지정된 loss 함수를 고려할 때, $s_n$과 $s_p$에 대한 그래디언트는 동일한 진폭을 가진다(2장에서 자세히 설명됨). 일부 극단적인 경우에는 예를 들어 $s_p$가 작고 $s_n$이 이미 0에 가까운 경우("그림 1(a)의 A"에서와 같이), 큰 그래디언트로 $s_n$에 계속해서 패널티를 가한다. 이는 비효율적이고 비합리적이다.

### Ambiguous convergence status: 
$s_n - s_p$을 최적화하는 것은 보통 $s_p - s_n = m$ (m은 마진)의 decision boundary를 초래한다. 이 decision boundary는 수렴을 위한 모호성을 허용한다(예를 들어, 그림 1(a)의 "T"와 "T'" 참조). 예를 들어, $T$는 $\{s_n, s_p\} = \{0.2, 0.5\}$이고 $T'$는 $\{s'_n, s'_p\} = \{0.4, 0.7\}$이다. 두 경우 모두 마진 $m = 0.3$을 얻지만, 서로 비교할 때 $s'_n$과 $s_p$ 사이의 간격은 단 0.1이다. 따라서 이 모호한 수렴은 특징 공간의 분리 가능성을 저해한다.

이러한 통찰을 바탕으로, 다른 유사도 점수들은 다른 패널티 강도를 가져야 한다는 직관에 도달했다. 유사도 점수가 최적점에서 멀리 벗어날수록 강한 패널티를 받아야 한다. 반대로 유사도 점수가 이미 최적점에 근접한 경우, 온화하게 최적화되어야 한다. 이를 위해 우선 $(\alpha_n s_n - \alpha_p s_p)$로 일반화하여 $s_n$과 $s_p$가 다른 속도로 학습할 수 있도록 독립적인 가중치 인자 $\alpha_n$과 $\alpha_p$를 도입한다. 그 다음 $s_n$과 $s_p$에 대해 $\alpha_n$과 $\alpha_p$를 $s_n$과 $s_p$에 대한 선형 함수로 구현하여 학습 속도를 적응형으로 만든다. 최적화 상태: 유사도 점수가 최적점에서 멀어질수록 가중치 인자가 커진다. 이러한 최적화 결과는 decision boundary $\alpha_n s_n - \alpha_p s_p = m$을 만들어내며, $(s_n, s_p)$ 공간에서 원형 모양을 형성한다. 따라서 제안된 loss 함수를 Circle loss라고 명명한다.

Circle loss는 단순함으로써 깊은 피처 학습의 특성을 본질적으로 재구성한다. 다음 세 가지 측면에서:

### First, a unified loss function. 
통합된 유사도 쌍 최적화 관점에서, 우리는 class 수준 레이블과 쌍별 레이블로 학습하는 두 가지 기본적인 학습 패러다임을 위한 통합된 loss 함수를 제안한다.

### Second, flexible optimization.
훈련 중에 $s_n$ (또는 $s_p$)으로 역전파되는 그라디언트는 $\alpha_n$ ($\alpha_p$)에 의해 증폭될 것이다. 최적화되지 않은 유사도 점수는 더 큰 가중치 인자를 가지며, 따라서 더 큰 그라디언트를 받게 된다. 그림 1(b)에 표시된 것처럼, A, B, C에 대한 최적화는 서로 다르다.

### Third, definite convergence status. 
원형 decision boundary에서, Circle loss는 특정 수렴 상태를 선호하며, 이는 3.3절에서 입증될 것이다. 이에 따라, 명확한 최적화 목표를 설정하고 특징 공간의 분리성을 향상시킨다.

# 2. A Unified Perspective

딥 피처 학습의 목표는 class 내 유사도 $s_p$를 최대화하고 class 간 유사도 $s_n$을 최소화하는 것입니다. 예를 들어, 코사인 유사도 지표를 사용할 때 $s_p \rightarrow 1$ 및 $s_n \rightarrow 0$을 기대합니다.

이를 위해, class 수준 레이블로 학습과 쌍별 레이블로 학습은 두 가지 기본적인 패러다임입니다. 이들은 전통적으로 분리되어 고려되며 loss 함수와 관련하여 서로 상당히 다릅니다. class 수준 레이블이 주어진 경우, 첫 번째 방법은 분류 loss 함수를 사용하여 각 훈련 샘플을 해당 타깃 class로 분류합니다. 예를 들어, L2-Softmax [21], 대 마진 softmax [15], Angular Softmax [16], NormFace [30], AM-Softmax [29], CosFace [32], ArcFace [2] 등이 있습니다. 이 방법들은 프록시 기반 학습으로 알려져 있으며, 각 class를 대표하는 프록시 집합과 샘플 간의 유사도를 최적화합니다. 반면, 쌍별 레이블이 주어진 경우, 두 번째 방법은 피처 공간에서 샘플 간의 쌍별 유사도(즉, 유사도 자체)를 직접 학습하므로 프록시가 필요 없습니다. 예를 들어, 대조 loss [5, 1], triplet loss [9, 22], Lifted-Structure loss [19], N-쌍 loss [24], 히스토그램 loss [27], Angular loss [33], 마진 기반 loss [38], Multi-Similarity loss [34] 등이 있습니다.

이 논문은 프록시 기반 또는 쌍별 유사도에 대한 선호 없이 통합된 관점에서 두 학습 접근 방식을 다룹니다. 피처 공간에서 단일 샘플 $x$를 주어진 상황에서, class 내 유사도 점수 $K$개와 class 간 유사도 점수 $L$개가 $x$와 연관되어 있다고 가정합시다. 이 유사도 점수들을 각각 $\{s^i_p\}$ ($i = 1, 2, \ldots, K$)와 $\{s^j_n\}$ ($j = 1, 2, \ldots, L$)으로 표기합니다.

각 $s^j_n$을 최소화하고 $s^i_p$을 최대화하기 위해, 우리는 통합된 loss 함수를 다음과 같이 제안합니다:
$$
\begin{align*}
\mathcal{L}_{uni} &= \log \left[ 1 + \sum_{i=1}^{K} \sum_{j=1}^{L} \exp(\gamma(s^j_n - s^i_p + m)) \right]
\\&= \log \left[ 1 + \sum_{j=1}^{L} \exp(\gamma(s^j_n + m)) \sum_{i=1}^{K} \exp(-\gamma s^i_p) \right]
\end{align*}
$$
여기서 $\gamma$는 스케일 인자이고 $m$은 유사도 분리를 향상시키기 위한 마진입니다. 이 loss 함수는 class 간 유사도를 줄이면서 class 내 유사도를 증가시키는 방향으로 작동합니다.

방정식 1은 직관적입니다. 이는 모든 유사도 쌍을 순회하며 $s^j_n - s^i_p$를 줄이는 것을 반복합니다. 우리는 이것이 triplet loss이나 분류 loss로 쉽게 변형될 수 있다는 점을 지적합니다.

class 수준 레이블을 사용할 때, 우리는 $x$와 가중치 벡터 $w_i$ ($i = 1, 2, \ldots, N$) 사이의 유사도 점수를 계산합니다. 여기서 $N$은 분류 계층에서의 훈련 class 수입니다. 구체적으로, 우리는 (비대상 가중치 벡터인) $w_j$에 대해 $N-1$개의 class 간 유사도 점수를 다음과 같이 계산합니다: $s^j_n = \frac{w_j^T x}{\|w_j\|\|x\|}$
또한, 우리는 하나의 class 내 유사도 점수 $s_p$를 계산합니다(상첨자 생략):$s_p = \frac{w_T^T x}{\|w_T\|\|x\|}$
여기서 $w_T$는 타깃 class의 가중치 벡터입니다.

이 전제 조건을 바탕으로 방정식 1은 AM-Softmax [29, 32], softmax cross-entropy loss의 중요한 변형으로 전환됩니다:
$$
\begin{align*}
\mathcal{L}_{am} &= \log \left[ 1 + \sum_{j=1}^{N-1} \exp(\gamma(s^j_n + m)) \exp(-\gamma s_p) \right]
\\ &= -\log \frac{\exp(\gamma(s_p - m))}{\exp(\gamma(s_p - m)) + \sum_{j=1}^{N-1} \exp(\gamma s^j_n)}
\end{align*}
$$
이 식에서 $\gamma$는 스케일 인자이고 $m$은 마진입니다. 이러한 식은 class 내 유사도를 증가시키고 class 간 유사도를 감소시키기 위한 목적으로 사용됩니다.

더 나아가 $m = 0$일 때, 방정식 2는 NormFace [30]로 더욱 단순화됩니다. 코사인 유사도를 내적으로 대체하고 $\gamma = 1$로 설정함으로써, 최종적으로 이는 Softmax loss로 변환됩니다.

쌍별 레이블이 주어졌을 때, 우리는 미니배치 내의 다른 특징들과 $x$ 사이의 유사도 점수를 계산합니다. 구체적으로, $j$번째 샘플인 $x_j$에 대해 부정적 샘플 집합 $\mathcal{N}$과의 유사도 $s^j_n$는 다음과 같이 계산됩니다:
\[ s^j_n = \frac{x^T_j x}{\|x_j\| \|x\|} \]
그리고 $i$번째 샘플인 $x_i$에 대한 긍정적 샘플 집합 $\mathcal{P}$과의 유사도 $s^i_p$는 다음과 같이 계산됩니다:
\[ s^i_p = \frac{x_i^T x}{\|x_i\| \|x\|} \]
따라서, $K = |\mathcal{P}|$, $L = |\mathcal{N}|$입니다. 방정식 1은 하드 마이닝(hard mining) [22, 8]과 함께 triplet loss로 변환됩니다:

$$
\begin{align*}
\mathcal{L}_{tri} &= \lim_{\gamma \to +\infty} -\frac{1}{\gamma} \mathcal{L}_{uni}
\\&= \lim_{\gamma \to +\infty} -\log \left[ 1 + \sum_{i=1}^{K} \sum_{j=1}^{L} \exp(\gamma (s^j_n - s^i_p + m)) \right]
\\&= \max[s^j_n - s^i_p]
\end{align*}
$$
이는 각 긍정적 샘플 $s^i_p$에 대해 가장 큰 부정적 유사도 $s^j_n$을 찾아 그 차이를 최대화하는 것을 목표로 합니다.

구체적으로, 방정식 3에서 $\sum \exp(\cdot)$ 연산은 Lifted-Structure loss [19], N-쌍 loss [24], 다중 유사도 loss [34] 등에 의해 사용되며, 샘플들 사이에서 "소프트" 하드 마이닝을 수행합니다. $\gamma$를 점차적으로 증가시키면 마이닝 강도가 강화되고, $\gamma \to +\infty$일 때, 이는 [22, 8]에서 설명된 전형적인 하드 마이닝으로 귀결됩니다.

그라디언트 분석에서, 방정식 2와 방정식 3은 triplet loss, softmax loss 및 그 여러 변형들을 보여줍니다. 이들은 모두 방정식 1의 특정 사례로 해석될 수 있으며, 즉, 모두 $s_n - s_p$를 최적화합니다. 단일 $s_p$와 $s_n$만 존재하는 가상 시나리오 하에서, 우리는 triplet loss과 AM-Softmax loss의 그라디언트를 시각화하고, 그로부터 다음과 같은 관찰을 도출합니다.

1. **loss 함수의 decision boundary에 도달하기 전**: loss이 그 decision boundary(그라디언트가 사라지는 지점)에 도달하기 전에, $s_p$와 $s_n$에 대한 그라디언트는 서로 동일합니다. 상태 A는 $\{s_n, s_p\} = \{0.8, 0.8\}$을 가지며, 이는 class 내 밀집도가 좋음을 나타냅니다. 그러나 A는 여전히 $s_p$에 대해 큰 그라디언트를 받아 최적화 중 유연성이 부족하다는 문제점을 드러냅니다.

2. **그라디언트의 일관성과 급격한 감소**: 그라디언트는 수렴 전까지 대략 일정하게 유지되다가 수렴 시점에 갑작스럽게 감소합니다. 상태 B는 decision boundary에 더 가깝게 위치하며, A에 비해 더 잘 최적화되어 있습니다. 그러나, loss 함수(triplet loss 및 AM-Softmax loss 모두)는 A와 B에 대해 대략적으로 동등한 패널티를 부과하므로 이 또한 유연성 부족의 또 다른 증거입니다.

3. **decision boundary의 문제**: decision boundary(하얀 점선)는 $s_n - s_p = m$에 평행합니다. 이 경계선 위의 어떤 두 점(예: 그림 1의 T와 T')도 $m$의 유사도 격차를 가지므로, 얻기 어려운 동일한 난이도를 지닙니다. 즉, $(s_n - s_p + m)$을 최소화하는 loss 함수는 수렴을 위해 T나 T'를 선호하지 않으며, 모호한 수렴 경향이 있습니다. 이 문제의 실험적 증거는 섹션 4.6에서 다룹니다.

이러한 문제들은 $s_n - s_p$를 최소화하는 최적화 방식에서 비롯되며, 이는 $s_n$을 줄이는 것이 $s_p$를 증가시키는 것과 동등하다는 점에서 나타납니다. 다음 섹션 3에서, 우리는 이러한 최적화 방식을 더 일반적인 방식으로 전환하여 더 높은 유연성을 촉진할 것입니다.

# 3. A New Loss Function  
## 3.1. Self-paced Weighting

새로운 loss 함수의 절에서는 최적화 유연성을 향상시키기 위해 각 유사도 점수가 현재 최적화 상태에 따라 자체적인 속도로 학습할 수 있도록 고려하고 있습니다. 마진 $m$ 항을 Eq. 1에서 제거하고 통합된 loss 함수를 제안된 Circle loss로 변환합니다:


$$
\begin{align*}
\mathcal{L}_{circle} &= \log \left[ 1 + \sum_{i=1}^K \sum_{j=1}^L \exp \left( \gamma (\alpha_j^n s^j_n - \alpha_i^p s^i_p) \right) \right]
\\&= \log \left[ 1 + \sum_{j=1}^L \exp(\gamma \alpha_j^n s^j_n) \sum_{i=1}^K \exp(-\gamma \alpha_i^p s^i_p) \right]
\end{align*}
$$


여기서 $\alpha_j^n$과 $\alpha_i^p$는 각각 부정적 및 긍정적 유사도 점수에 대한 비음수 가중치 인자입니다.

Eq. 4는 Eq. 1을 일반화하여 $s^j_n - s^i_p$ 대신에 $(\alpha_j^n s^j_n - \alpha_i^p s^i_p)$를 사용함으로써 유도됩니다. 훈련 중에, $\alpha_j^n s^j_n - \alpha_i^p s^i_p$에 대한 그라디언트는 $\alpha_j^n$ ($\alpha_i^p$)과 곱해져서 $s^j_n$ ($s^i_p$)에 역전파됩니다. 유사도 점수가 그 최적점에서 멀리 벗어날 때 (예: $s^j_n$에 대한 $O_n$과 $s^i_p$에 대한 $O_p$), 큰 가중치 인자를 받아 큰 그라디언트 업데이트를 받아야 합니다. 이를 위해, 다음과 같은 자기 조절 방식으로 $\alpha_i^p$와 $\alpha_j^n$를 정의합니다:


$$\alpha_i^p = [O_p - s^i_p]_+$$
$$\alpha_j^n = [s^j_n - O_n]_+$$


여기서 $[ \cdot ]_+$는 "제로에서 컷오프" 연산으로, $\alpha_i^p$와 $\alpha_j^n$가 비음수임을 보장합니다. 이러한 접근 방식은 각 유사도 점수가 개별적으로 가장 필요한 부분에서 가장 큰 학습을 받도록 하여 최적화 과정의 유연성을 크게 향상시킵니다.

토론에서, 코사인 유사도의 재조정은 현대 분류 loss에서 흔히 사용되는 방법입니다. 일반적으로 모든 유사도 점수는 같은 스케일 인자 $\gamma$를 공유합니다. 이러한 동일한 재조정은 softmax 값이 특정 class에 속하는 샘플의 확률로 고려될 때 자연스럽게 느껴집니다. 반면, Circle loss는 재조정 전에 각 유사도 점수에 독립적인 가중치 인자를 곱하여 동일한 재조정의 제약을 없애고 보다 유연한 최적화를 허용합니다. 이러한 재가중(또는 재조정) 전략은 단순한 최적화 개선뿐만 아니라 기본적인 해석에도 중요한 의미를 가지고 있습니다. Circle loss는 샘플을 타겟 class로 분류하는 데 큰 확률을 부여하는 기존 해석을 버리고, 두 학습 패러다임과 호환되는 유사도 쌍 최적화 관점을 취합니다.

## 3.2. Within-class and Between-class Margins
 $s_n - s_p$를 최적화하는 loss 함수에서 마진 $m$을 추가하는 것은 최적화를 강화합니다. $s_n$과 $s_p$가 대칭 위치에 있을 때, $s_n$에 대한 양의 마진은 $s_p$에 대한 음의 마진과 같으므로 단일 마진 $m$만 필요합니다. 그러나 Circle loss에서는 $s_n$과 $s_p$가 비대칭 위치에 있어 각각에 대해 별도의 마진이 필요하며, 이는 다음과 같이 표현됩니다:


$$
\mathcal{L}_{circle} = \log \left[ 1 + \sum_{j=1}^L \exp(\gamma \alpha_j^n (s^j_n - \Delta_n)) \sum_{i=1}^K \exp(-\gamma \alpha_i^p (s^i_p - \Delta_p)) \right]
$$


여기서 $\Delta_n$과 $\Delta_p$는 각각 class 간 및 class 내 마진입니다. Circle loss의 설정에서 Eq. 6은 $s^i_p > \Delta_p$와 $s^j_n < \Delta_n$을 기대합니다. 이를 통해 decision boundary를 도출하며, 이진 분류의 경우 decision boundary는 $\alpha_n (s_n - \Delta_n) - \alpha_p (s_p - \Delta_p) = 0$에서 달성됩니다. Eq. 5와 결합하여, decision boundary는 다음과 같이 주어집니다:

$$
(s_n-\frac{O_n+\Delta_n}{2})^2+(s_p-\frac{O_p+\Delta_p}{2})^2
$$

여기서 $C = ((O_n - \Delta_n)^2 + (O_p - \Delta_p)^2)/4$입니다. 이 방정식은 $s_n$과 $s_p$에 대한 개별적인 조정을 통해 더 정밀한 최적화와 decision boundary를 설정할 수 있게 합니다.

Eq. 7은 decision boundary가 원형임을 보여줍니다. 이 원의 중심은 $s_n = (O_n + \Delta_n)/2$ 및 $s_p = (O_p + \Delta_p)/2$에 위치하고, 그 반지름은 $\sqrt{C}$입니다. Circle loss에는 $O_p$, $O_n$, $\gamma$, $\Delta_p$, $\Delta_n$ 등 다섯 개의 하이퍼파라미터가 있습니다. 이 중 $O_p$, $O_n$, $\Delta_p$, $\Delta_n$을 간소화하여 $O_p = 1+m$, $O_n = -m$, $\Delta_p = 1-m$, $\Delta_n = m$으로 설정함으로써, Eq. 7의 decision boundary는 다음과 같이 단순화됩니다:

$$(s_n - 0)^2 + (s_p - 1)^2 = 2m^2$$

Eq. 8에서 정의된 decision boundary를 통해 Circle loss의 또 다른 직관적인 해석을 얻을 수 있습니다. 이는 $s_p \to 1$과 $s_n \to 0$을 최적화하는 것을 목표로 하며, 매개변수 $m$은 decision boundary의 반지름을 제어하고, 이를 완화 인자로 볼 수 있습니다. 즉, Circle loss는 $s^i_p > 1 - m$ 및 $s^j_n < m$을 기대합니다.

따라서 이제 두 개의 하이퍼파라미터만 고려하면 되는데, 그것은 스케일 인자 $\gamma$와 완화 마진 $m$입니다. $m$과 $\gamma$의 영향을 4.5절에서 실험적으로 분석할 예정입니다. 이러한 설정은 Circle loss가 더 유연한 최적화와 더 정밀한 class 간 및 class 내 마진 조절을 가능하게 합니다.


# 3.3. The Advantages of Circle Loss
$s^j_n$과 $s^i_p$에 대한 Circle loss의 그라디언트는 다음과 같이 유도됩니다:

$$\frac{\partial \mathcal{L}_{circle}}{\partial s^j_n} = Z \frac{\exp(\gamma((s^j_n)^2 - m^2))}{\sum_{l=1}^L \exp(\gamma((s_l^n)^2 - m^2))} \gamma (s^j_n + m),$$

$$\frac{\partial \mathcal{L}_{circle}}{\partial s^i_p} = Z \frac{\exp(\gamma((s^i_p - 1)^2 - m^2))}{\sum_{k=1}^K \exp(\gamma((s_k^p - 1)^2 - m^2))} \gamma (s^i_p - 1 - m),$$


여기서 $Z$는 정규화 상수로 $Z = 1 - \exp(-\mathcal{L}_{circle})$입니다.

이 그라디언트는 유사도 점수 $s^j_n$와 $s^i_p$가 최적의 값에서 멀어질수록 큰 값을 가짐으로써, 이 점수들을 최적의 방향으로 더 강하게 조정하도록 합니다. 이를 통해 더 빠르고 효율적인 학습이 가능하며, 이는 특히 이진 분류 시나리오나 단일 $s_n$ 및 $s_p$ 설정에서 유용합니다. 이 문서의 나머지 부분에서는 다양한 $m$ 설정하에 그라디언트를 시각화하고, 이를 바탕으로 Circle loss의 세 가지 주요 관찰 결과를 도출합니다:

1. **강력한 그라디언트 반응**: $s_n$ 및 $s_p$가 그들의 목표 값에서 벗어날 때, 그라디언트의 크기가 증가하여 더 빠른 조정을 유도합니다.
2. **유연한 최적화 가능성**: 다양한 $m$ 값에 대한 그라디언트의 조정을 통해 다양한 학습 시나리오에 맞게 최적화 과정을 맞춤 설정할 수 있습니다.
3. **효율적인 학습 진행**: 각 유사도 점수의 최적화 상태에 따라 그라디언트를 조정함으로써 학습이 보다 목표 지향적이고 효율적으로 진행됩니다.

이러한 그라디언트 접근 방식은 Circle loss를 사용하는 학습 시스템에서 효과적인 수렴을 촉진하고, 복잡한 학습 환경에서도 견고한 성능을 발휘할 수 있도록 지원합니다.

Circle loss는 여러 핵심적인 이점들을 제공하는데, 이는 loss 함수의 동적 최적화에 기반합니다:

1. **균형 잡힌 최적화:** 일반적으로 $s_n - s_p$를 최소화하는 loss 함수는 $s_p$와 $s_n$에 대해 동일한 그라디언트 크기를 가지고, 유연성이 부족합니다. 반면, Circle loss는 동적인 패널티 강도를 제공하여, 한 쌍의 유사도 점수 중 하나가 다른 것보다 더 잘 최적화되었다면, 상대적으로 더 적게 최적화된 점수에 더 큰 그라디언트를 할당합니다. 예를 들어, $s_p$가 $s_n$보다 더 잘 최적화되어 있을 경우 $s_n$에 더 큰 그라디언트를 부여하여 $s_n$의 우월성을 감소시킵니다. 이를 통해 더 균형 잡힌 최적화가 가능하며, 이에 대한 실험적 증거는 섹션 4.6에서 다룰 예정입니다.

2. **점진적으로 감소하는 그라디언트:** 훈련 초기에는 유사도 점수가 최적점에서 멀리 떨어져 있기 때문에 큰 그라디언트를 받습니다. 훈련이 진행됨에 따라 유사도 점수가 수렴점에 접근하면서 그라디언트는 점차 감소합니다. 이는 훈련 중에 부드러운 최적화를 가능하게 하며, $\gamma$ 설정에 따라 학습 효과의 견고함을 보여주는 실험 결과가 섹션 4.5에서 제시됩니다.

3. **더 명확한 수렴 목표:** Circle loss는 원형의 decision boundary를 가지고 있으며, 특정 지점 $T$를 선호하는 경향이 있습니다. 이는 $T$가 $s_p$와 $s_n$ 사이의 갭이 가장 작기 때문에 수렴하기가 더 쉬워서입니다. 반면, $T'$와 같은 다른 지점들은 더 큰 갭을 가지고 있어 상대적으로 수렴하기 어렵습니다. 기존의 $s_n - s_p$를 최소화하는 loss은 모든 점에서 동일한 난이도를 가지는 균일한 decision boundary를 가집니다. 실험적으로 Circle loss는 수렴 후에 더 집중된 유사도 분포를 보여주며, 이는 섹션 4.6과 그림 5에서 자세히 설명됩니다.

이러한 특성들은 Circle loss가 다양한 학습 환경에서 유연하고 효과적인 최적화를 달성할 수 있도록 지원합니다.

# 4. Experiment

4장에서는 Circle loss의 효과성을 두 가지 기본적인 학습 접근 방법, 즉 class 수준 레이블과 쌍별 레이블을 사용한 학습에서 종합적으로 평가합니다. 전자의 접근 방법에서는 얼굴 인식(4.2절)과 인물 재식별(4.3절) 작업에서 우리의 방법을 평가합니다. 후자의 접근 방법에서는 상대적으로 작은 데이터셋을 사용하여 세밀한 이미지 검색(4.4절)을 수행합니다. 이러한 데이터셋은 쌍별 레이블 학습을 장려합니다. 우리는 Circle loss가 두 설정에서 모두 유능함을 보여줍니다. 4.5절에서는 두 하이퍼파라미터, 즉 Eq. 6의 스케일 인자 \( \gamma \)와 Eq. 8의 완화 인자 \( m \)의 영향을 분석합니다. 우리는 Circle loss가 합리적인 설정에서 견고함을 보여줍니다. 마지막으로, 4.6절에서는 실험을 통해 Circle loss의 특성을 확인합니다.