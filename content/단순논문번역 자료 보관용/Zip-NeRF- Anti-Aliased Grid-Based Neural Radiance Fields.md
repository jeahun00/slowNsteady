
# Abstract

Neural Radiance Field training은 NeRF의 공간 좌표에서 색상 및 체적 밀도로의 학습된 매핑에서 그리드 기반 표현을 사용함으로써 가속화될 수 있습니다. 그러나 이러한 그리드 기반 접근 방식은 규모에 대한 명확한 이해가 부족하여 보통 지그재그 모양의 aliasing 또는 장면 내용의 누락 형태로 aliasing을 도입합니다. Anti-aliasing은 이전에 mip-NeRF 360에 의해 처리되었으며, 이는 광선에 따른 점이 아닌 원뿔을 따라 부피를 고려합니다. 하지만 이 접근법은 현재의 그리드 기반 기술과는 본질적으로 호환되지 않습니다. 우리는 렌더링 및 신호 처리에서의 아이디어가 mip-NeRF 360과 같은 그리드 기반 모델과 Instant NGP를 결합하여 오류율을 8%에서 77% 낮추고, mip-NeRF 360보다 24배 더 빠르게 훈련되는 기술을 구성하는 데 어떻게 사용될 수 있는지 보여줍니다.

Neural Radiance Fields (NeRF)에서는 3D 장면의 체적 표현을 모델링하기 위해 신경망이 훈련됩니다. NeRF는 새로운 장면 뷰를 ray tracing을 통해 렌더링할 수 있도록 하는 방식입니다. NeRF는 view synthesis, generative media, robotics, computational photography와 같은 작업에서 효과적인 도구로 입증되었습니다.

원래 NeRF 모델은 다층 퍼셉트론(MLP)을 사용하여 공간 좌표에서 색상 및 밀도로의 매핑을 매개변수화했습니다. MLP는 컴팩트하고 표현력이 뛰어나지만 훈련 속도가 느립니다. 최근 연구에서는 voxel-그리드 같은 데이터 구조로 MLP를 대체하거나 보완하여 훈련 속도를 가속화했습니다. 한 예로 Instant NGP (iNGP)는 coarse와 fine 그리드의 피라미드를 사용하여 작은 MLP로 처리되는 학습된 특징을 구성하여 훈련을 크게 가속화합니다.

원래 NeRF 모델은 또한 aliasing 문제도 있었습니다: NeRF는 광선을 따라 개별 점에 대해 reasoning하며, 이는 렌더링된 이미지에서 "jaggies"를 생성하고, NeRF가 규모에 대해 reasoning하는 능력을 제한합니다. Mip-NeRF는 광선 대신 원뿔을 투영하여 이 문제를 해결했습니다. mip-NeRF와 그 후속 모델 mip-NeRF 360은 이 접근 방식이 현실 세계의 어려운 장면에서 높은 정확도로 렌더링을 가능하게 한다는 것을 보여주었습니다.

안타깝게도, 빠른 훈련과 anti-aliasing의 두 문제에 대한 진전은 처음에는 호환되지 않는 것으로 보입니다. 이는 mip-NeRF의 anti-aliasing 전략이 positional encoding의 사용에 크게 의존하기 때문입니다. 현재의 그리드 기반 접근 방식은 positional encoding을 사용하지 않으며, 대신 단일 3D 좌표에서 그리드 계층으로 보간된 학습된 특징을 사용합니다. 대부분의 접근 방식은 iNGP와 같은 그리드 기반 NeRF 모델에서 역렌더링에 자연스럽게 일반화되지 않습니다.

이 연구에서 우리는 multisampling, statistics 및 signal processing의 아이디어를 활용하여 iNGP의 그리드 피라미드를 mip-NeRF 360의 프레임워크에 통합했습니다. 우리는 이 모델을 속도, mip-NeRF와의 유사성, 지퍼 같은 aliasing 인공물을 수정하는 능력 때문에 "Zip-NeRF"라고 부릅니다. mip-NeRF 360 벤치마크에서 Zip-NeRF는 오류율을 최대 19% 줄이고 이전 state-of-the-art보다 24배 빠르게 훈련합니다. 더 철저하게 aliasing 및 규모를 측정하는 멀티스케일 벤치마크에서 Zip-NeRF는 오류율을 최대 77%까지 줄입니다.
# 1. Preliminaries

Mip-NeRF 360과 Instant NGP (iNGP)는 모두 NeRF와 유사합니다. [19]: 픽셀은 3D 광선을 투영하고 광선을 따라 거리에 있는 위치를 특징화하여 렌더링됩니다. 이러한 특징은 신경망에 입력되며, 출력은 색상을 렌더링하기 위해 알파 컴포지션됩니다. 훈련은 훈련 이미지의 픽셀에 해당하는 광선을 반복적으로 투영하고, 각 픽셀의 렌더링된 색상과 관찰된 색상의 차이를 최소화하는 방식(gradient descent를 통해)으로 구성됩니다.

Mip-NeRF 360과 iNGP는 광선을 따라 좌표를 매개변수화하는 방식에서 크게 다릅니다. Mip-NeRF 360에서는 광선이 [$t_i, t_{i+1}$]의 간격으로 세분화되며, 각 간격은 다변량 Gaussian으로 근사화된 원뿔형 프러스텀을 나타냅니다. Gaussian에 대한 positional encoding은 큰 MLP [2]에 입력으로 사용됩니다. 반면, iNGP는 크기가 다른 3D 그리드의 계층 구조로 삼선 보간하여 작은 MLP [21]에 대한 특징 벡터를 생성합니다. 우리의 모델은 Mip-NeRF 360의 전체 프레임워크와 iNGP의 특징화 접근 방식을 결합하지만, 이 두 접근 방식을 단순히 결합하면 두 가지 형태의 aliasing이 발생합니다.

1. Instant NGP의 특징 그리드 접근 방식은 Mip-NeRF 360의 규모 인식 통합 positional encoding 기술과 호환되지 않습니다. 따라서 iNGP에 의해 생성된 특징은 공간 좌표와 관련하여 aliasing되어 aliasing된 렌더링을 생성합니다. 우리는 섹션 2에서 사전 필터링된 iNGP 특징을 계산하기 위한 멀티샘플링 유사 솔루션을 소개하여 이를 해결합니다.

2. iNGP를 사용하면 훈련 속도가 극적으로 가속화되지만, 이는 Mip-NeRF 360의 온라인 증류 접근 방식에서 발생하는 문제를 드러냅니다. 이 문제는 광선을 따라 aliasing되어 카메라가 움직일 때 장면 내용이 불규칙하게 사라지는 "z-aliasing"을 유발합니다. 우리는 섹션 3에서 온라인 증류를 감독하기 위해 손실 함수를 계산할 때 각 광선을 따라 사전 필터링하는 새로운 손실 함수로 이를 해결합니다.

# 2. Spatial Anti-Aliasing

Mip-NeRF는 원뿔형 프러스텀인 서브 볼륨 내 좌표의 positional encoding에 대한 적분을 근사하는 특징을 사용합니다. 이는 Fourier 특징에서 나타나며, Gaussian의 표준 편차보다 특징 사인파의 주기가 클 때 특징의 진폭이 작아집니다. 이러한 특징은 서브 볼륨의 공간적 위치를 서브 볼륨의 크기보다 큰 파장에서만 나타냅니다. 이 특징이 위치와 규모를 모두 인코딩하기 때문에, 이를 소비하는 MLP는 3D 장면의 멀티스케일 표현을 학습하여 anti-aliased 이미지를 렌더링할 수 있습니다. iNGP와 같은 그리드 기반 표현은 본질적으로 서브 볼륨을 쿼리할 수 없으며, 대신 단일 지점에서 삼선 보간을 사용하여 MLP에서 사용할 특징을 구성합니다. 이는 규모나 aliasing에 대해 reasoning할 수 없는 학습된 모델을 초래합니다.

우리는 각 원뿔형 프러스텀을 등방성 Gaussian 세트로 변환하고, 멀티샘플링 및 특징 가중 감소 조합을 사용하여 이를 해결합니다: 비등방성 서브 볼륨은 먼저 그 형태를 근사하는 포인트 세트로 변환되고, 각 포인트는 일정 규모의 등방성 Gaussian으로 가정됩니다. 이 등방성 가정은 그리드의 값이 평균이 0임을 활용하여 서브 볼륨에 대한 특징 그리드의 실제 적분을 근사할 수 있게 합니다. 이러한 감소된 특징을 평균화함으로써, 우리는 iNGP 그리드에서 규모를 인식하는 사전 필터링된 특징을 얻습니다. 시각화를 위해 그림 2를 참조하십시오.

Anti-aliasing은 그래픽스 문헌에서 잘 연구되어 있습니다. Mip mapping [31] (mip-NeRF의 이름을 딴)은 빠른 anti-aliasing을 가능하게 하는 데이터 구조를 사전에 계산하지만, 이 접근 방식을 iNGP의 해시 기반 데이터 구조에 어떻게 적용할 수 있는지는 불분명합니다. Supersampling 기술 [8]은 anti-aliasing에 대해 강제 접근법을 취하고 많은 샘플을 사용합니다; 우리는 이것이 우리의 접근 방식보다 덜 효과적이고 더 비싸다는 것을 증명할 것입니다. 멀티샘플링 기술 [11]은 소수의 샘플을 구성한 다음, 이들 멀티샘플에서 정보를 풀링하여 비싼 렌더링 프로세스에 제공되는 집합 표현을 만듭니다 — 이는 우리의 접근 방식을 닮은 전략입니다.

## Multisampling

Mip-NeRF [2]를 따른다면, 각 픽셀은 반지름 $rt$의 원뿔에 해당한다고 가정합니다. 여기서 $t$는 광선을 따른 거리입니다. 광선 [$t_0, t_1$]을 따라 주어진 간격에서, 우리는 그 원뿔형 프러스텀의 형태를 근사하는 멀티샘플 세트를 구성하고자 합니다. 우리는 각도가 $\theta_j$인 6점 육각형 패턴을 사용합니다:


$$\theta = [0, \frac{2\pi}{3}, \frac{4\pi}{3}, 3\pi, \frac{5\pi}{3}, \pi],$$



이는 원의 한 회전을 따라 선형적으로 간격이 떨어진 각도이며, 60도씩 이동된 두 개의 삼각형 쌍을 형성합니다. 광선을 따른 거리 $t_j$는 다음과 같습니다:

$$t_j = t_0 + \frac{t_\delta \left( t_1^2 + 2t_1^2\mu + \frac{3}{\sqrt{7}}\left(\frac{2j}{5}-1\right) \sqrt{ \left( t_\delta^2 - t_\mu^2 \right)^2 + 4t_4 \mu } \right)}{t_\delta^2 + 3t_\mu^2},$$

여기서 $t_\mu = \frac{(t_0 + t_1)}{2}, t_\delta = \frac{(t_1 - t_0)}{2}$

이는 \[$t_0, t_1$\]에서 선형적으로 간격을 두고, 프러스텀의 원뿔형 기저에 가까운 질량을 집중시키도록 이동 및 조정됩니다. 우리의 멀티샘플 좌표는 광선을 기준으로 다음과 같습니다:


$$\left\{
\begin{array}{c}
\left[\begin{array}{c}
rt_j \cos(\theta_j) / \sqrt{2} \\
rt_j \sin(\theta_j) / \sqrt{2} \\
t_j
\end{array}\right]
\end{array}
\right\} \quad j = 0, 1, \ldots, 5.$$


이 3D 좌표는 광선 방향이 세 번째 벡터이고, 처음 두 벡터는 광선에 수직인 임의의 프레임으로부터 광선의 기원으로 이동된 직교기저를 곱하여 월드 좌표로 회전됩니다. 구성에 의해, 이러한 멀티샘플의 평균 및 분산(광선 및 광선에 수직)에 해당하는 샘플은 원뿔형 프러스텀의 것과 정확히 일치합니다. 이는 mip-NeRF Gaussian [2]와 유사하게 구성됩니다(자세한 내용은 보충 자료를 참조하십시오). 훈련 중에는 무작위로 각 패턴을 회전 및 반전시키고, 렌더링 중에는 결정론적으로 모든 패턴을 30도씩 번갈아 회전 및 반전시킵니다. 두 전략의 시각화는 그림 3을 참조하십시오.

우리는 이 6개의 멀티샘플 $\{x_j\}$을 표준 편차 $\sigma_j$를 가진 등방성 Gaussian의 평균으로 사용합니다. 우리는 $\sigma_j$를 $rt_j / \sqrt{2}$로 설정하고, 이는 하이퍼파라미터에 의해 조정됩니다. 실험에서는 0.5로 설정됩니다. iNGP 그리드는 입력 좌표가 제한된 도메인에 놓여야 하기 때문에, 우리는 mip-NeRF 360 [3]의 수축 함수를 적용합니다. 이러한 Gaussian이 등방성이기 때문에, 우리는 mip-NeRF 360에서 사용된 Kalman 필터 접근법의 효율적인 대안을 사용하여 이 수축에 의해 유도된 스케일 인자를 계산할 수 있습니다. 자세한 내용은 보충 자료를 참조하십시오.

## Downweighting

멀티샘플링은 aliasing을 줄이는 효과적인 도구이지만, 각 멀티샘플에 대해 단순한 삼선 보간을 사용하는 것은 여전히 높은 주파수에서 aliasing을 초래합니다(그림 2(d) 참조). 각 개별 멀티샘플에 대한 anti-alias 보간을 위해, 우리는 각 규모에서의 특징을 재가중치합니다. 이때 각 멀티샘플의 등방성 Gaussian이 각 그리드 셀에 얼마나 적합한지에 반비례하도록 합니다. Gaussian이 보간되는 셀보다 훨씬 큰 경우, 보간된 특징은 신뢰할 수 없으므로 가중치를 낮춰야 합니다. Mip-NeRF의 IPE 특징은 유사한 해석을 가집니다.

iNGP에서는 각 그리드 또는 해시 $\{V_\ell\}$에 있는 좌표 $\mathbf{x}$로 보간할 때, $\mathbf{x}$를 그리드의 선형 크기 $n_\ell$로 스케일링하고 $V_\ell$로 삼선 보간을 수행하여 $c_\ell$ 길이 벡터를 얻습니다. 대신 우리는 평균 $\{\mathbf{x}_j\}$와 표준 편차 $\{\sigma_j\}$를 가진 멀티샘플된 등방성 Gaussian 세트를 보간합니다. Gaussian CDF를 통해 reasoning함으로써 각 Gaussian의 PDF의 일부가 $\{V_\ell\}$에 보간되는 $[-1/2n_\ell, 1/2n_\ell]^3$ 큐브 내에 있는 비율을 계산할 수 있으며, 이는 스케일 의존적 다운웨이팅 계수 $\omega_{j,\ell} = \operatorname{erf}\left( \frac{1}{\sqrt{2}\sigma_j n_\ell} \right)$로 사용됩니다. 섹션 4에서 자세히 설명한 바와 같이, 우리는 $\{V_\ell\}$에 대해 가중치 감소를 적용하여, $\{V_\ell\}$의 값이 보통 분포되고 평균이 0이 되도록 장려합니다. 이 평균 0 가정은 각 멀티샘플의 Gaussian에 대한 기대 그리드 특징을 $\omega_j \cdot f_{j,\ell} + (1 - \omega_j) \cdot 0 = \omega_j \cdot f_{j,\ell}$로 근사할 수 있게 합니다. 이를 통해, 우리는 각 멀티샘플의 보간된 특징의 가중 평균을 취하여 원뿔형 프러스텀을 특징화하는 기대 특징을 근사할 수 있습니다:

$$f_\ell = \operatorname{mean}_j (\omega_{j,\ell} \cdot \operatorname{trilerp}(n_\ell \cdot \mathbf{x}_j; V_\ell)).$$

이 특징 집합 $\{f_\ell\}$은 결합되어 MLP에 대한 입력으로 제공됩니다. 이는 iNGP에서와 같습니다. 우리는 또한 특징화된 $\{\omega_{j,\ell}\}$의 버전을 결합합니다. 자세한 내용은 보충 자료를 참조하십시오.

# 3. Z-Aliasing and Proposal Supervision

이전에 설명한 멀티샘플링 및 다운웨이팅 접근 방식이 공간적인 aliasing을 줄이는 효과적인 방법이지만, 광선을 따라 aliasing의 추가적인 원인이 있습니다. 이를 우리는 z-aliasing이라고 부릅니다. 이 z-aliasing은 mip-NeRF 360의 제안 MLP가 장면 기하학에 대한 상한값을 생성하도록 학습하는 방식에서 기인합니다. 훈련 및 렌더링 중에 광선을 따라 간격이 반복적으로 평가되어 다음 샘플링 라운드에 의해 재샘플링되는 히스토그램을 생성합니다. 최종 샘플 세트만이 NeRF MLP에 의해 렌더링됩니다. Mip-NeRF 360은 이 접근 방식이 이전의 이미지 재구성을 사용한 학습 전략과 비교하여 속도와 렌더링 품질을 크게 향상시킨다는 것을 보여주었습니다 [2]. 우리는 mip-NeRF 360의 제안 MLP가 입력 좌표에서 출력 체적 밀도로의 매핑이 매끄럽지 않게 학습하는 경향이 있음을 관찰합니다. 이는 광선이 장면 내용을 "건너뛰는" 아티팩트를 초래하며, 이는 그림 4에서 볼 수 있습니다. 이 아티팩트는 mip-NeRF 360에서 경미하지만, MLP 대신 iNGP 백엔드를 제안 네트워크로 사용하면(따라서 모델의 빠른 최적화 능력 증가) 카메라가 z축을 따라 이동할 때 일반적이고 시각적으로 두드러집니다.

mip-NeRF 360에서 z-aliasing의 근본 원인은 제안 네트워크를 감독하는 데 사용되는 "interlevel loss"입니다. 이는 NeRF와 제안 히스토그램 빈에 동등한 손실을 할당하여 겹침이 부분적이거나 완전할 때만 제안 히스토그램 빈을 페널티화합니다. 이 문제를 해결하기 위해, 우리는 거리와 관련하여 매끄럽고 연속적인 대안 손실을 제시합니다. 그림 6에서 두 손실 함수의 비교를 참조하십시오.

## Blurring a Step Function

광선을 따라 거리에 대해 매끄러운 손실 함수를 설계하려면, 우리는 먼저 조각별 상수 계단 함수를 연속적인 조각별 선형 함수로 변환하는 기술을 구축해야 합니다. 이산 1차원 신호를 매끄럽게 하는 것은 간단하며, 박스 필터(또는 Gaussian 필터 등)로 이산 컨볼루션만 필요합니다. 하지만 끝점이 연속적인 조각별 상수 함수의 경우 문제가 복잡해지며, 계단 함수의 각 간격의 끝점이 임의의 위치에 있을 수 있습니다. 계단 함수를 래스터화하고 컨볼루션을 수행하는 것은 매우 좁은 히스토그램 빈의 일반적인 경우에는 실행 가능한 해결책이 아닙니다.

따라서 새로운 알고리즘이 필요합니다. 간격 $i$의 끝점이 $(x_i, x_{i+1})$이고 $y_i$가 간격 $i$ 내의 계단 함수 값인 계단 함수 $(\mathbf{x}, \mathbf{y})$를 고려해 봅시다. 우리는 이 계단 함수를 반지름 $r$인 직사각형 펄스로 컨볼루션하고자 합니다. 이 펄스는 1로 적분되며 $\|x\| < r$/(2r)에서 Iverson 브래킷을 사용합니다. 이 직사각형 펄스와 계단 함수의 단일 간격 $i$의 컨볼루션은 매듭이 $(x_i - r, 0), (x_i + r, y_i), (x_{i+1} - r, y_i), (x_{i+1} + r, 0)$인 조각별 선형 사다리꼴이며, 조각별 선형 스플라인이 각 스플라인 매듭에 위치한 스케일된 델타 함수의 이중 적분이라는 사실을 관찰합니다 [12]. 이를 통해, 덧셈이 적분과 교환된다는 사실과 함께, 우리는 다음과 같이 직사각형 펄스와 계단 함수를 효율적으로 컨볼루션할 수 있습니다: 계단 함수의 각 끝점 $x_i$를 두 개의 부호 있는 델타 함수로 변환하여 $x_i - r$ 및 $x_i + r$에 위치시키고, 그 값은 인접한 $y$ 값 사이의 변화에 비례합니다. 우리는 이 델타 함수들을 교차(정렬을 통해)하고, 이 정렬된 델타 함수들을 두 번 적분합니다(의사코드는 보충 자료의 알고리즘 1을 참조하십시오). 이를 통해, 우리는 anti-alias된 손실 함수를 구성할 수 있습니다.

## Anti-Aliased Interlevel Loss

Mip-NeRF 360의 제안 감독 접근 방식은 NeRF ($\mathbf{s}, \mathbf{w}$)와 제안 모델 ($\hat{\mathbf{s}}, \hat{\mathbf{w}}$)에 의해 생성된 유사한 계단 함수를 입력으로 받는 손실 함수를 요구합니다. 이 두 계단 함수는 히스토그램입니다. $\mathbf{s}$와 $\hat{\mathbf{s}}$는 끝점 위치의 벡터이고, $\mathbf{w}$와 $\hat{\mathbf{w}}$는 가중치 벡터로, 합이 1 이하이며, $w_i$는 계단 함수의 간격 $i$에서 장면 내용이 얼마나 보이는지를 나타냅니다. 각 $s_i$는 어떤 정규화 함수 $g(\cdot)$에 따라 실제 메트릭 거리 $t_i$의 정규화된 함수입니다. 나중에 이에 대해 논의할 것입니다. $\mathbf{s}$와 $\hat{\mathbf{s}}$는 동일하지 않으며, 각 히스토그램의 끝점이 다릅니다.

제안 네트워크를 훈련하여 NeRF가 예측한 장면 기하학의 상한을 제한하고 aliasing을 도입하지 않도록 하려면, $\mathbf{s}, \mathbf{w}$와 $\hat{\mathbf{s}}, \hat{\mathbf{w}}$ 사이의 거리를 측정할 수 있는 손실 함수가 필요합니다. 이는 광선을 따라 번역에 대해 매끄럽습니다. 이를 위해 우리는 NeRF 히스토그램 ($\mathbf{s}, \mathbf{w}$)을 이전에 구축한 알고리즘을 사용하여 블러 처리한 후, 이 블러된 분포를 제안 히스토그램 $\hat{\mathbf{s}}$의 간격 세트로 다시 샘플링하여 새로운 히스토그램 가중치 $\mathbf{w}^{\hat{\mathbf{s}}}$를 생성합니다. 이 절차는 그림 5에 설명되어 있습니다. 블러된 NeRF 가중치를 제안 히스토그램 공간으로 다시 샘플링한 후, 우리의 손실 함수는 $\mathbf{w}^{\hat{\mathbf{s}}}$와 $\hat{\mathbf{w}}$의 요소별 함수입니다:

$$\mathcal{L}_{\text{prop}}(\mathbf{s}, \mathbf{w}, \hat{\mathbf{s}}, \hat{\mathbf{w}}) = \sum_i \frac{1}{w_i} \max(0, \nabla(\mathbf{w}^{\hat{\mathbf{s}}}_i) - \hat{\mathbf{w}}_i)^2. \quad (5)
$$
이 손실은 mip-NeRF 360의 손실(스톱-그래디언트가 있는 반-이차 카이제곱 손실)과 유사하지만, 블러링 및 다시 샘플링을 통해 생성된 $\mathbf{w}^{\hat{\mathbf{s}}}$는 aliasing을 방지합니다.

## Normalizing Metric Distance

mip-NeRF 360과 마찬가지로, 우리는 광선을 따라 메트릭 거리를 $t \in [t_{near}, t_{far}]$로 매개변수화하고, 정규화된 거리 $s \in [0, 1]$로 변환합니다(여기서 $t_{near}$와 $t_{far}$는 수동으로 정의된 근거리와 원거리 평면 거리입니다). 렌더링은 메트릭 거리 $t$를 사용하지만, 재샘플링 및 제안 감독은 정규화된 거리 $s$를 사용하며, 이는 두 변수 사이의 전단사 함수 $g(\cdot)$에 의해 정의됩니다. mip-NeRF 360에서 사용되는 interlevel loss는 거리의 단조 변환에 대해 불변이므로 $g(\cdot)$의 선택에 영향을 받지 않습니다. 그러나 우리의 anti-aliased loss에서의 사전 필터링은 이 불변성을 제거하며, mip-NeRF 360의 손실을 사용하면 치명적인 실패를 초래하므로 새로운 정규화를 구성해야 합니다. 이를 위해, 우리는 새로운 거듭제곱 변환을 구성합니다 [5, 29]:

$$\mathcal{P}(x, \lambda) = \frac{\lambda - 1}{\lambda} \left( \left( \frac{x}{\lambda - 1} + 1 \right)^\lambda - 1 \right). \quad (6)$$

이 함수의 기울기는 원점에서 1이므로, 광선 근처의 정규화된 거리는 메트릭 거리에 비례합니다(비제로 근거리 평면 거리 $t_{near}$를 조정할 필요가 없습니다). 하지만 원점에서 멀리 떨어진 메트릭 거리는 log-distance [22] ($\lambda = 0$) 또는 inverse-distance [3] ($\lambda = -1$)와 유사하게 곡선이 됩니다. 이를 통해 우리는 서로 다른 정규화 간에 매끄럽게 보간할 수 있으며, 서로 다른 이산 함수를 교체하는 대신 이를 사용할 수 있습니다. 그림 7에서 $\mathcal{P}(x, \lambda)$의 시각화와 이전 정규화 접근 방식의 비교를 참조하십시오. 이는 $g(x) = \mathcal{P}(x, -1.5)$와 같으며, $s \in [0, 1/2]$일 때는 대략 선형인 곡선이지만, $s \in [1/2, 1]$일 때는 inverse 및 inverse-square 사이에 있습니다.

# 4. Results

우리 모델은 JAX [6]에서 구현되었으며 mip-NeRF 360 코드베이스 [20]를 기반으로 하고 있습니다. 여기서 iNGP의 보컬 그리드와 해시의 피라미드를 사용하여 mip-NeRF 360에서 사용된 큰 MLP를 대체하는 재구현을 포함합니다. 우리의 전체 모델 아키텍처는 섹션 2와 3에서 소개된 anti-aliasing 조정을 제외하고 mip-NeRF 360과 동일하며, 여기서 설명하는 몇 가지 추가 수정 사항도 포함됩니다.

mip-NeRF 360과 마찬가지로, 우리는 각 64개의 샘플을 포함한 두 라운드의 제안 샘플링을 사용하고, 최종 NeRF 샘플링 라운드에서는 32개의 샘플을 사용합니다. 우리의 anti-aliased interlevel loss는 두 라운드의 제안 샘플링 모두에 적용되며, 첫 번째 라운드에서는 $r = 0.03$, 두 번째 라운드에서는 $r = 0.003$의 직사각형 펄스 너비를 사용하고, 손실 곱셈자는 0.01입니다. 우리는 각 제안 샘플링 라운드마다 별도의 제안 iNGP와 MLP를 사용하며, 우리의 NeRF MLP는 iNGP보다 훨씬 큰 뷰 종속 브랜치를 사용합니다. 자세한 내용은 보충 자료를 참조하십시오.

iNGP에 대해 우리가 한 작지만 중요한 수정 사항 중 하나는 피라미드 그리드와 해시에 저장된 특징 코드에 정규화된 가중치 감소를 적용하는 것입니다: $\sum_\ell \text{mean}(V_\ell^2)$. 각 피라미드 레벨 $V_\ell$의 제곱된 그리드/해시 값의 평균 합을 페널티화함으로써, 우리는 모든 값의 합을 페널티화하는 단순한 해결책과는 매우 다른 행동을 유도합니다. 이는 거친 스케일이 미세한 스케일보다 훨씬 더 큰 정도로 페널티화되기 때문입니다. 이 간단한 트릭은 매우 효과적입니다. 이는 가중치 감소가 없는 경우와 비교하여 성능을 크게 향상시키고, 단순 가중치 감소보다 훨씬 뛰어난 성능을 발휘합니다. 우리는 모든 실험에서 이 정규화된 가중치 감소에 대해 0.1의 손실 곱셈자를 사용합니다.

우리 모델은 JAX [6]에서 구현되었으며 mip-NeRF 360 코드베이스 [20]를 기반으로 하고 있습니다. 여기서 iNGP의 보컬 그리드와 해시의 피라미드를 사용하여 mip-NeRF 360에서 사용된 큰 MLP를 대체하는 재구현을 포함합니다. 우리의 전체 모델 아키텍처는 섹션 2와 3에서 소개된 anti-aliasing 조정을 제외하고 mip-NeRF 360과 동일하며, 여기서 설명하는 몇 가지 추가 수정 사항도 포함됩니다.

mip-NeRF 360과 마찬가지로, 우리는 각 64개의 샘플을 포함한 두 라운드의 제안 샘플링을 사용하고, 최종 NeRF 샘플링 라운드에서는 32개의 샘플을 사용합니다. 우리의 anti-aliased interlevel loss는 두 라운드의 제안 샘플링 모두에 적용되며, 첫 번째 라운드에서는 $r = 0.03$, 두 번째 라운드에서는 $r = 0.003$의 직사각형 펄스 너비를 사용하고, 손실 곱셈자는 0.01입니다. 우리는 각 제안 샘플링 라운드마다 별도의 제안 iNGP와 MLP를 사용하며, 우리의 NeRF MLP는 iNGP보다 훨씬 큰 뷰 종속 브랜치를 사용합니다. 자세한 내용은 보충 자료를 참조하십시오.

iNGP에 대해 우리가 한 작지만 중요한 수정 사항 중 하나는 피라미드 그리드와 해시에 저장된 특징 코드에 정규화된 가중치 감소를 적용하는 것입니다: $\sum_\ell \text{mean}(V_\ell^2)$. 각 피라미드 레벨 $V_\ell$의 제곱된 그리드/해시 값의 평균 합을 페널티화함으로써, 우리는 모든 값의 합을 페널티화하는 단순한 해결책과는 매우 다른 행동을 유도합니다. 이는 거친 스케일이 미세한 스케일보다 훨씬 더 큰 정도로 페널티화되기 때문입니다. 이 간단한 트릭은 매우 효과적입니다. 이는 가중치 감소가 없는 경우와 비교하여 성능을 크게 향상시키고, 단순 가중치 감소보다 훨씬 뛰어난 성능을 발휘합니다. 우리는 모든 실험에서 이 정규화된 가중치 감소에 대해 0.1의 손실 곱셈자를 사용합니다.

## 360 Dataset

우리 모델은 mip-NeRF 360의 확장판이기 때문에, 해당 논문에서 제시된 "360" 벤치마크를 동일한 평가 절차를 사용하여 평가합니다 [3]. 우리는 NeRF [19], mip-NeRF [2], NeRF++ [36], mip-NeRF 360, iNGP [21] (최근 연구 [32]에서 가져온 조정된 하이퍼파라미터를 사용하여), 그리고 이 논문의 기여 없이 mip-NeRF 360과 iNGP를 단순히 결합한 베이스라인을 평가합니다. 모든 장면에 대한 평균 오류 메트릭은 표 2에 나와 있으며(장면 메트릭에 대한 자세한 내용은 보충 자료를 참조하십시오), 이 네 가지 접근 방식의 렌더링은 그림 1에 나와 있습니다. 우리의 모델, mip-NeRF 360, 그리고 우리의 "mip-NeRF 360 + iNGP" 베이스라인은 모두 8개의 NVIDIA Tesla V100-SXM2-16GB GPU에서 훈련되었습니다. 다른 베이스라인은 다른 가속기에서 훈련되었으며(TPU는 NeRF, mip-NeRF 및 NeRF++에 사용되었고, 단일 NVIDIA 3090은 iNGP에 사용되었습니다) 비교를 가능하게 하기 위해 실행 시간이 우리의 하드웨어 성능에 맞게 재조정되었습니다. 우리의 모델의 렌더링 시간(이 작업의 초점이 아님)은 0.9초이며, mip-NeRF 360은 7.4초, 우리의 mip-NeRF 360 + iNGP 베이스라인은 0.2초가 소요됩니다.

우리 모델은 이 벤치마크에서 mip-NeRF 360(이 작업의 이전 최첨단)을 크게 능가합니다. 우리는 RMSE, DSSIM 및 LPIPS에서 각각 11%, 17%, 19%의 감소를 관찰했습니다. 또한, 우리 모델은 mip-NeRF 360보다 24배 더 빠르게 훈련됩니다. iNGP와 비교했을 때, 우리의 오류 감소는 더욱 두드러집니다: RMSE, DSSIM 및 LPIPS에서 각각 28%, 42%, 37% 감소했지만, 우리의 모델은 iNGP보다 약 6배 더 느리게 훈련됩니다. 결합된 "mip-NeRF 360 + iNGP" 베이스라인은 mip-NeRF 360보다 훨씬 빠르게 훈련되며(우리 모델보다 거의 3배 빠르게 훈련됨) mip-NeRF 360과 비교할만한 오류율을 생성하며 iNGP보다 뛰어납니다. 이러한 베이스라인에 대한 우리 모델의 이미지 품질 향상은 시각적 검사 시 명확히 드러납니다(그림 1 및 보충 비디오 참조).

## Multiscale 360 Dataset

360 데이터셋에는 도전적인 장면 콘텐츠가 포함되어 있지만, 규모의 함수로 렌더링 품질을 측정하지는 않습니다. 이 데이터셋은 중앙 객체 주위를 일정한 거리로 카메라를 회전시켜 캡처되었기 때문에 학습된 모델은 다양한 이미지 해상도나 중앙 객체로부터의 다른 거리에서 잘 일반화되지 않습니다. 따라서 우리는 mip-NeRF [2]에서 사용된 멀티스케일 Blender 데이터셋과 유사한 더 도전적인 평가 절차를 사용합니다: 우리는 각 이미지를 [1, 2, 4, 8]의 스케일 팩터로 이중삼차 다운샘플링된 4개의 이미지 세트로 변환합니다. 다운샘플링된 이미지는 장면 중심에서 확대된 추가적인 훈련/테스트 뷰를 대리합니다. 훈련 중에 우리는 각 광선의 스케일 팩터에 데이터 항을 곱하고, 테스트 시 각 스케일을 개별적으로 평가합니다. 이는 모델이 스케일에 걸쳐 일반화하도록 요구함으로써 재구성 난이도를 크게 증가시키며, 특히 거친 스케일에서 aliasing 아티팩트를 매우 두드러지게 만듭니다.

표 1에서 우리는 iNGP, mip-NeRF 360, 우리의 mip-NeRF 360 + iNGP 베이스라인, 그리고 여러 절삭 연구와 우리의 모델을 평가합니다. mip-NeRF 360이 규모를 고려할 수 있기 때문에 합리적으로 성능을 발휘하지만, 우리 모델은 여전히 가장 미세한 스케일에서 8%, 가장 거친 스케일에서 17% RMSE를 줄이며 24배 더 빠릅니다. 규모에 대한 메커니즘이나 anti-aliasing이 없는 mip-NeRF 360 + iNGP 베이스라인은 성능이 저조합니다: 우리의 RMSE는 가장 미세한 스케일에서 19%, 가장 거친 스케일에서 55% 낮으며, 가장 거친 스케일에서 DSSIM과 LPIPS는 77% 낮습니다. 이 개선 사항은 그림 8에서 볼 수 있습니다. 우리의 mip-NeRF 360 + iNGP 베이스라인은 일반적으로 iNGP보다 성능이 우수합니다(예상대로 가장 거친 스케일 제외).

표 1에서는 또한 우리 모델의 절삭 연구를 포함합니다. (A) 멀티샘플링 및 다운웨이팅이 비활성화된 "단순" 샘플링을 사용하면 품질이 크게 저하되며, (B) 멀티샘플 예산에 맞추기 위해 6배 팩터로 초샘플링해도 정확도가 향상되지 않습니다 [8]. (C, D) 원뿔 내에서 무작위로 샘플을 변동시키면 거친 스케일에서 성능이 약간 향상되지만, 그 정도는 미미합니다. (E) 멀티샘플링과 (F) 다운웨이팅을 개별적으로 비활성화하면 각 구성 요소의 영향을 측정할 수 있으며, 두 구성 요소 모두 동일하게 기여합니다. (G) $\omega$를 특징으로 사용하지 않으면 성능이 약간 저하됩니다. (H) 각 mip-NeRF Gaussian에서 6개의 무작위 포인트를 샘플링하거나 (G) 각 Gaussian [14]에서 무변환 제어 포인트를 사용하는 대체 멀티샘플링 접근 방식은 우리의 육각형 패턴에 대한 경쟁력 있는 대안이지만, 약간 느리거나 정확도가 떨어집니다. (J) anti-aliased interlevel loss를 비활성화하면 단일 이미지 메트릭에 거의 영향을 미치지 않지만, 비디오 결과에서 z-aliasing 아티팩트를 유발합니다. (K) 정규화된 가중치 감소를 비활성화하면 정확도가 크게 감소하며, 비정규화된 가중치 감소를 사용하는 것은 성능이 저조합니다. (L) iNGP의 작은 뷰 종속 MLP를 사용하는 것은 정확도를 감소시킵니다.

## Sample Efficiency

우리의 멀티스케일 벤치마크에서 anti-aliased interlevel loss를 절삭하는 것은 품질을 크게 저하시키지 않습니다. 이는 mip-NeRF 360(공정한 비교를 위해 우리 모델도 마찬가지로) 각 광선에 대해 많은 샘플을 사용하여 z-aliasing을 줄이기 때문입니다. mip-NeRF 360의 z-aliasing 취약성을 드러내기 위해, 그림 9에서 우리는 NeRF와 제안 네트워크 모두에 대해 샘플 수를 절반으로 줄이고, $r$과 훈련 반복 횟수를 두 배로 늘리면서 테스트 세트 PSNR을 그래프로 나타냅니다. 우리의 anti-aliased loss는 샘플 수가 많을 때 mip-NeRF 360의 손실보다 약간 더 우수하지만, 샘플 수가 줄어들면 베이스라인 손실은 치명적으로 실패하는 반면, 우리의 손실은 우아하게 저하됩니다.

즉, 장면 내용 누락의 가장 심각한 z-aliasing 아티팩트(그림 4에 표시됨)는 정지 이미지의 작은 벤치마크에서 측정하기 어렵습니다. 이는 장면 내용이 특정 거리에서만 사라지며, 테스트 세트가 이를 탐지하지 못할 수 있기 때문입니다. z-aliasing에 대한 데모와 aliasing이 수정된 우리 모델의 렌더링을 보려면 보충 비디오를 참조하십시오.



(A) Using “naive” sampling with our multisam- pling and downweighting disabled (which corresponds to the approach used in NeRF and iNGP) significantly de- grades quality
(B) supersampling [8] by a 6× fac- tor to match our multisample budget does not improve ac- curacy. 
(C, D) Randomly jittering these naive samples within the cone being cast improves performance at coarse scales, but only slightly. Individually disabling 
(E) multi- sampling and 
(F) downweighting lets us measure the im- pact of each component; they both contribute evenly. 
(G) Not using ω as a feature hurts performance slightly. Alter- native multisampling approaches like 
(H) sampling 6 random points from each mip-NeRF Gaussian or 
(G) using 7 unscented transform control points from each Gaussian [14] as multisamples are competitive alternatives to our hexag- onal pattern, but have slightly worse speeds and/or accura- cies. (J) Disabling our anti-aliased interlevel loss has little effect on our single-image metrics, but causes z-aliasing ar- tifacts in our video results. (K) Disabling our normalized weight decay reduces accuracy significantly, and (L) using non-normalized weight decay performs poorly. (M) Using iNGP’s small view-dependent MLP decreases accuracy.